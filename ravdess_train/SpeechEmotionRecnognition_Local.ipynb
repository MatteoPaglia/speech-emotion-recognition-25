{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bifSi62Ixrqr"
   },
   "source": [
    "# Step 3: Dataset Setup\n",
    "## Different options\n",
    "- First one is downloading using a script that places the data in the download folder (usually recommended)\n",
    "- Second one is uploading the dataset to your personal/institutional Google Drive and load it from there ([Read More](https://saturncloud.io/blog/google-colab-how-to-read-data-from-my-google-drive/))\n",
    "- Place the download script directly here on colab\n",
    "\n",
    "You are free to do as you please in this phase.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üîß PROJECT ENVIRONMENT INFO\n",
      "================================================================================\n",
      "Python Version: 3.10.0\n",
      "PyTorch Version: 2.10.0+cu128\n",
      "NumPy Version: 2.2.6\n",
      "Current Working Directory: d:\\Roba da D\\Poli\\ML Vision\\speech-emotion-recognition-25\n",
      "\n",
      "‚úÖ CUDA is AVAILABLE\n",
      "   GPU Device: NVIDIA GeForce RTX 5060 Ti\n",
      "   CUDA Version: 12.8\n",
      "   Number of GPUs: 1\n",
      "   Default Device: cuda\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Import all required libraries\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "\n",
    "# Setup project path\n",
    "NOTEBOOK_DIR = Path(os.getcwd())\n",
    "PROJECT_ROOT = NOTEBOOK_DIR.parent if NOTEBOOK_DIR.name == 'ravdess_train' else NOTEBOOK_DIR\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "# Print system and environment info\n",
    "print(\"=\"*80)\n",
    "print(\"üîß PROJECT ENVIRONMENT INFO\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Python Version: {sys.version.split()[0]}\")\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"NumPy Version: {np.__version__}\")\n",
    "print(f\"Current Working Directory: {os.getcwd()}\")\n",
    "print(f\"Project Root: {PROJECT_ROOT}\")\n",
    "print()\n",
    "\n",
    "# Check CUDA availability\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úÖ CUDA is AVAILABLE\")\n",
    "    print(f\"   GPU Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   CUDA Version: {torch.version.cuda}\")\n",
    "    print(f\"   Number of GPUs: {torch.cuda.device_count()}\")\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    print(f\"‚ùå CUDA is NOT available - Using CPU\")\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(f\"   Default Device: {device}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "DiWQTaTbxeIc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Download RAVDESS (locale) ---\n",
      "‚úì RAVDESS gi√† presente: d:\\Roba da D\\Poli\\ML Vision\\speech-emotion-recognition-25\\data\\ravdess\n",
      "Numero di file: 2880\n",
      "‚úÖ Downloaded RAVDESS dataset locally in d:\\Roba da D\\Poli\\ML Vision\\speech-emotion-recognition-25\\data\\ravdess...\n"
     ]
    }
   ],
   "source": [
    "from utils.download_dataset_local import dowload_ravdess_local\n",
    "\n",
    "dataset_path = dowload_ravdess_local()\n",
    "if dataset_path:\n",
    "    print(f\"‚úÖ Downloaded RAVDESS dataset locally in {dataset_path}...\")\n",
    "else:\n",
    "    print(\"‚ùå RAVDESS dataset download failed.\")\n",
    "    \n",
    "ravdess_path = dataset_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üîÑ CREAZIONE DATASET E DATALOADER - RAVDESS\n",
      "================================================================================\n",
      "‚úÖ Usando dataset da: d:\\Roba da D\\Poli\\ML Vision\\speech-emotion-recognition-25\\data\\ravdess\n",
      "\n",
      "üìä Statistiche del dataset RAVDESS:\n",
      "\n",
      "========================================\n",
      "üìä ANALISI RAVDESS TRAINING SET\n",
      "========================================\n",
      "üîπ Samples Totali: 1440\n",
      "üîπ Attori (20): [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
      "   - Maschi:  10\n",
      "   - Femmine: 10\n",
      "\n",
      "üé≠ Distribuzione Emozioni:\n",
      "   - Angry     :  320 ( 22.2%) ‚ñà‚ñà‚ñà‚ñà\n",
      "   - Happy     :  320 ( 22.2%) ‚ñà‚ñà‚ñà‚ñà\n",
      "   - Neutral   :  480 ( 33.3%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   - Sad       :  320 ( 22.2%) ‚ñà‚ñà‚ñà‚ñà\n",
      "----------------------------------------\n",
      "üìä Statistiche del dataset RAVDESS:\n",
      "\n",
      "========================================\n",
      "üìä ANALISI RAVDESS VALIDATION SET\n",
      "========================================\n",
      "üîπ Samples Totali: 144\n",
      "üîπ Attori (2): [21, 22]\n",
      "   - Maschi:  1\n",
      "   - Femmine: 1\n",
      "\n",
      "üé≠ Distribuzione Emozioni:\n",
      "   - Angry     :   32 ( 22.2%) ‚ñà‚ñà‚ñà‚ñà\n",
      "   - Happy     :   32 ( 22.2%) ‚ñà‚ñà‚ñà‚ñà\n",
      "   - Neutral   :   48 ( 33.3%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   - Sad       :   32 ( 22.2%) ‚ñà‚ñà‚ñà‚ñà\n",
      "----------------------------------------\n",
      "üìä Statistiche del dataset RAVDESS:\n",
      "\n",
      "========================================\n",
      "üìä ANALISI RAVDESS TEST SET\n",
      "========================================\n",
      "üîπ Samples Totali: 144\n",
      "üîπ Attori (2): [23, 24]\n",
      "   - Maschi:  1\n",
      "   - Femmine: 1\n",
      "\n",
      "üé≠ Distribuzione Emozioni:\n",
      "   - Angry     :   32 ( 22.2%) ‚ñà‚ñà‚ñà‚ñà\n",
      "   - Happy     :   32 ( 22.2%) ‚ñà‚ñà‚ñà‚ñà\n",
      "   - Neutral   :   48 ( 33.3%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   - Sad       :   32 ( 22.2%) ‚ñà‚ñà‚ñà‚ñà\n",
      "----------------------------------------\n",
      "\n",
      "================================================================================\n",
      "üì¶ DATALOADER SUMMARY\n",
      "================================================================================\n",
      "Train Dataloader:      45 batch √ó 32 samples = 1440 totali\n",
      "Validation Dataloader: 5 batch √ó 32 samples = 144 totali\n",
      "Test Dataloader:       5 batch √ó 32 samples = 144 totali\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from dataset.custom_ravdess_dataset import CustomRAVDESSDataset\n",
    "from utils.get_dataset_statistics import print_dataset_stats\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üîÑ CREAZIONE DATASET E DATALOADER - RAVDESS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Verifica percorso\n",
    "if not ravdess_path or not Path(ravdess_path).exists():\n",
    "    raise ValueError(f\"‚ùå Dataset RAVDESS non trovato in: {ravdess_path}\")\n",
    "\n",
    "print(f\"‚úÖ Usando dataset da: {ravdess_path}\\n\")\n",
    "\n",
    "# Crea i dataset\n",
    "train_dataset = CustomRAVDESSDataset(dataset_root=ravdess_path, split='train')\n",
    "val_dataset = CustomRAVDESSDataset(dataset_root=ravdess_path, split='validation')\n",
    "test_dataset = CustomRAVDESSDataset(dataset_root=ravdess_path, split='test')\n",
    "\n",
    "# Crea i dataloader\n",
    "batch_size = 32\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "# Riepilogo dataloader\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üì¶ DATALOADER SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Train Dataloader:      {len(train_dataloader)} batch √ó {batch_size} samples = {len(train_dataset)} totali\")\n",
    "print(f\"Validation Dataloader: {len(val_dataloader)} batch √ó {batch_size} samples = {len(val_dataset)} totali\")\n",
    "print(f\"Test Dataloader:       {len(test_dataloader)} batch √ó {batch_size} samples = {len(test_dataset)} totali\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Download IEMOCAP (locale) ---\n",
      "‚úì IEMOCAP gi√† presente: d:\\Roba da D\\Poli\\ML Vision\\speech-emotion-recognition-25\\data\\iemocap\n",
      "Numero di file: 81249\n",
      "‚úÖ Downloaded IEMOCAP dataset locally in d:\\Roba da D\\Poli\\ML Vision\\speech-emotion-recognition-25\\data\\iemocap\\IEMOCAP_full_release...\n"
     ]
    }
   ],
   "source": [
    "# Ricarica il modulo per usare la versione fixata\n",
    "import importlib\n",
    "import sys\n",
    "if 'utils.download_dataset_local' in sys.modules:\n",
    "    importlib.reload(sys.modules['utils.download_dataset_local'])\n",
    "\n",
    "from utils.download_dataset_local import dowload_iemocap_local\n",
    "\n",
    "iemocap_dataset_path = dowload_iemocap_local()\n",
    "if iemocap_dataset_path:\n",
    "    print(f\"‚úÖ Downloaded IEMOCAP dataset locally in {iemocap_dataset_path}...\")\n",
    "else:\n",
    "    print(\"‚ùå IEMOCAP dataset download failed.\")\n",
    "    \n",
    "iemocap_path = iemocap_dataset_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üîç DEBUG - VERIFICA PERCORSI IEMOCAP\n",
      "================================================================================\n",
      "1Ô∏è‚É£  Percorso passato: d:\\Roba da D\\Poli\\ML Vision\\speech-emotion-recognition-25\\data\\iemocap\\IEMOCAP_full_release\n",
      "\n",
      "2Ô∏è‚É£  Percorso esiste: True\n",
      "\n",
      "3Ô∏è‚É£  Contenuto di d:\\Roba da D\\Poli\\ML Vision\\speech-emotion-recognition-25\\data\\iemocap\\IEMOCAP_full_release:\n",
      "   - Documentation (DIR)\n",
      "   - Session1 (DIR)\n",
      "   - Session2 (DIR)\n",
      "   - Session3 (DIR)\n",
      "   - Session4 (DIR)\n",
      "   - Session5 (DIR)\n",
      "\n",
      "4Ô∏è‚É£  Ricerca cartelle Session:\n",
      "   Trovate: 5 cartelle Session\n",
      "   - Session1\n",
      "   - Session2\n",
      "   - Session3\n",
      "\n",
      "5Ô∏è‚É£  Dentro Session1:\n",
      "   - dialog\n",
      "   - sentences\n",
      "\n",
      "6Ô∏è‚É£  Percorso wav: d:\\Roba da D\\Poli\\ML Vision\\speech-emotion-recognition-25\\data\\iemocap\\IEMOCAP_full_release\\Session1\\sentences\\wav\n",
      "   Esiste: True\n",
      "   Contiene 28 elementi:\n",
      "      - Ses01F_impro01 (DIR)\n",
      "      - Ses01F_impro02 (DIR)\n",
      "      - Ses01F_impro03 (DIR)\n",
      "      - Ses01F_impro04 (DIR)\n",
      "      - Ses01F_impro05 (DIR)\n",
      "\n",
      "7Ô∏è‚É£  Percorso label: d:\\Roba da D\\Poli\\ML Vision\\speech-emotion-recognition-25\\data\\iemocap\\IEMOCAP_full_release\\Session1\\dialog\\EmoEvaluation\n",
      "   Esiste: True\n",
      "   Trovati 28 file .txt\n",
      "      - Ses01F_impro01.txt\n",
      "      - Ses01F_impro02.txt\n",
      "      - Ses01F_impro03.txt\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# DEBUG: Verifica percorsi IEMOCAP\n",
    "print(\"=\"*80)\n",
    "print(\"üîç DEBUG - VERIFICA PERCORSI IEMOCAP\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "iemocap_debug_path = iemocap_path\n",
    "print(f\"1Ô∏è‚É£  Percorso passato: {iemocap_debug_path}\\n\")\n",
    "\n",
    "# Controlla se il percorso esiste\n",
    "print(f\"2Ô∏è‚É£  Percorso esiste: {Path(iemocap_debug_path).exists()}\\n\")\n",
    "\n",
    "# Lista cosa c'√® dentro\n",
    "if Path(iemocap_debug_path).exists():\n",
    "    print(f\"3Ô∏è‚É£  Contenuto di {iemocap_debug_path}:\")\n",
    "    for item in Path(iemocap_debug_path).iterdir():\n",
    "        print(f\"   - {item.name} {'(DIR)' if item.is_dir() else ''}\")\n",
    "    print()\n",
    "\n",
    "# Cerca le cartelle Session\n",
    "print(f\"4Ô∏è‚É£  Ricerca cartelle Session:\")\n",
    "session_folders = list(Path(iemocap_debug_path).glob(\"Session*\"))\n",
    "print(f\"   Trovate: {len(session_folders)} cartelle Session\")\n",
    "for s in session_folders[:3]:\n",
    "    print(f\"   - {s.name}\")\n",
    "print()\n",
    "\n",
    "# Se ci sono Session, controlla la struttura di una\n",
    "if session_folders:\n",
    "    session1 = session_folders[0]\n",
    "    print(f\"5Ô∏è‚É£  Dentro {session1.name}:\")\n",
    "    for item in (session1).iterdir():\n",
    "        print(f\"   - {item.name}\")\n",
    "    print()\n",
    "    \n",
    "    # Controlla wav folder\n",
    "    wav_path = session1 / \"sentences\" / \"wav\"\n",
    "    print(f\"6Ô∏è‚É£  Percorso wav: {wav_path}\")\n",
    "    print(f\"   Esiste: {wav_path.exists()}\")\n",
    "    if wav_path.exists():\n",
    "        wav_items = list(wav_path.iterdir())\n",
    "        print(f\"   Contiene {len(wav_items)} elementi:\")\n",
    "        for item in wav_items[:5]:\n",
    "            print(f\"      - {item.name} {'(DIR)' if item.is_dir() else ''}\")\n",
    "    print()\n",
    "    \n",
    "    # Controlla label folder\n",
    "    label_path = session1 / \"dialog\" / \"EmoEvaluation\"\n",
    "    print(f\"7Ô∏è‚É£  Percorso label: {label_path}\")\n",
    "    print(f\"   Esiste: {label_path.exists()}\")\n",
    "    if label_path.exists():\n",
    "        label_items = list(label_path.glob(\"*.txt\"))\n",
    "        print(f\"   Trovati {len(label_items)} file .txt\")\n",
    "        for item in label_items[:3]:\n",
    "            print(f\"      - {item.name}\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üîÑ CREAZIONE DATASET E DATALOADER - IEMOCAP\n",
      "================================================================================\n",
      "‚úÖ Usando dataset da: d:\\Roba da D\\Poli\\ML Vision\\speech-emotion-recognition-25\\data\\iemocap\\IEMOCAP_full_release\n",
      "\n",
      "‚úÖ Caricate 5531 etichette\n",
      "üîç Raccogliendo campioni audio...\n",
      "‚úÖ Raccolti 2943 campioni audio validi\n",
      "   - Solo campioni improvvisati\n",
      "   - Emozioni: ['neutral', 'happy', 'sad', 'angry', 'happy']\n",
      "üìä Statistiche del dataset IEMOCAP:\n",
      "\n",
      "============================================================\n",
      "üìä ANALISI IEMOCAP TRAINING SET\n",
      "============================================================\n",
      "\n",
      "üîπ SAMPLES TOTALI: 1678\n",
      "üîπ SESSIONI: ['1', '2', '3']\n",
      "üîπ SPEAKER UNICI (session, gender): 6\n",
      "   Elenco: [('1', 'F'), ('1', 'M'), ('2', 'F'), ('2', 'M'), ('3', 'F'), ('3', 'M')]\n",
      "üîπ IMPROVVISAZIONI UNICHE: 12\n",
      "   Elenco: ['01', '02', '03', '04', '05', '05a', '05b', '06', '07', '08', '08a', '08b']\n",
      "\n",
      "üë• SPEAKER INDEPENDENCE (per verificare leakage):\n",
      "   - Sessione 1: (Ses1, F), (Ses1, M)\n",
      "   - Sessione 2: (Ses2, F), (Ses2, M)\n",
      "   - Sessione 3: (Ses3, F), (Ses3, M)\n",
      "\n",
      "üé≠ DISTRIBUZIONE EMOZIONI:\n",
      "   - Angry     :  174 ( 10.4%) ‚ñà‚ñà\n",
      "   - Happy     :  472 ( 28.1%) ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   - Neutral   :  638 ( 38.0%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   - Sad       :  394 ( 23.5%) ‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "üìã DISTRIBUZIONE CAMPIONI PER SESSIONE:\n",
      "   - Sessione 1:  521 ( 31.0%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      ‚îî‚îÄ Angry     :  62 ( 11.9%)\n",
      "      ‚îî‚îÄ Happy     : 132 ( 25.3%)\n",
      "      ‚îî‚îÄ Neutral   : 223 ( 42.8%)\n",
      "      ‚îî‚îÄ Sad       : 104 ( 20.0%)\n",
      "   - Sessione 2:  530 ( 31.6%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      ‚îî‚îÄ Angry     :  22 (  4.2%)\n",
      "      ‚îî‚îÄ Happy     : 191 ( 36.0%)\n",
      "      ‚îî‚îÄ Neutral   : 217 ( 40.9%)\n",
      "      ‚îî‚îÄ Sad       : 100 ( 18.9%)\n",
      "   - Sessione 3:  627 ( 37.4%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      ‚îî‚îÄ Angry     :  90 ( 14.4%)\n",
      "      ‚îî‚îÄ Happy     : 149 ( 23.8%)\n",
      "      ‚îî‚îÄ Neutral   : 198 ( 31.6%)\n",
      "      ‚îî‚îÄ Sad       : 190 ( 30.3%)\n",
      "------------------------------------------------------------\n",
      "‚úÖ Dataset initialized: 1678 train samples\n",
      "‚úÖ Caricate 5531 etichette\n",
      "üîç Raccogliendo campioni audio...\n",
      "‚úÖ Raccolti 2943 campioni audio validi\n",
      "   - Solo campioni improvvisati\n",
      "   - Emozioni: ['neutral', 'happy', 'sad', 'angry', 'happy']\n",
      "üìä Statistiche del dataset IEMOCAP:\n",
      "\n",
      "============================================================\n",
      "üìä ANALISI IEMOCAP VALIDATION SET\n",
      "============================================================\n",
      "\n",
      "üîπ SAMPLES TOTALI: 534\n",
      "üîπ SESSIONI: ['4']\n",
      "üîπ SPEAKER UNICI (session, gender): 2\n",
      "   Elenco: [('4', 'F'), ('4', 'M')]\n",
      "üîπ IMPROVVISAZIONI UNICHE: 8\n",
      "   Elenco: ['01', '02', '03', '04', '05', '06', '07', '08']\n",
      "\n",
      "üë• SPEAKER INDEPENDENCE (per verificare leakage):\n",
      "   - Sessione 4: (Ses4, F), (Ses4, M)\n",
      "\n",
      "üé≠ DISTRIBUZIONE EMOZIONI:\n",
      "   - Angry     :   84 ( 15.7%) ‚ñà‚ñà‚ñà\n",
      "   - Happy     :  195 ( 36.5%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   - Neutral   :  174 ( 32.6%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   - Sad       :   81 ( 15.2%) ‚ñà‚ñà‚ñà\n",
      "\n",
      "üìã DISTRIBUZIONE CAMPIONI PER SESSIONE:\n",
      "   - Sessione 4:  534 (100.0%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      ‚îî‚îÄ Angry     :  84 ( 15.7%)\n",
      "      ‚îî‚îÄ Happy     : 195 ( 36.5%)\n",
      "      ‚îî‚îÄ Neutral   : 174 ( 32.6%)\n",
      "      ‚îî‚îÄ Sad       :  81 ( 15.2%)\n",
      "------------------------------------------------------------\n",
      "‚úÖ Dataset initialized: 534 validation samples\n",
      "‚úÖ Caricate 5531 etichette\n",
      "üîç Raccogliendo campioni audio...\n",
      "‚úÖ Raccolti 2943 campioni audio validi\n",
      "   - Solo campioni improvvisati\n",
      "   - Emozioni: ['neutral', 'happy', 'sad', 'angry', 'happy']\n",
      "üìä Statistiche del dataset IEMOCAP:\n",
      "\n",
      "============================================================\n",
      "üìä ANALISI IEMOCAP TEST SET\n",
      "============================================================\n",
      "\n",
      "üîπ SAMPLES TOTALI: 731\n",
      "üîπ SESSIONI: ['5']\n",
      "üîπ SPEAKER UNICI (session, gender): 2\n",
      "   Elenco: [('5', 'F'), ('5', 'M')]\n",
      "üîπ IMPROVVISAZIONI UNICHE: 8\n",
      "   Elenco: ['01', '02', '03', '04', '05', '06', '07', '08']\n",
      "\n",
      "üë• SPEAKER INDEPENDENCE (per verificare leakage):\n",
      "   - Sessione 5: (Ses5, F), (Ses5, M)\n",
      "\n",
      "üé≠ DISTRIBUZIONE EMOZIONI:\n",
      "   - Angry     :   31 (  4.2%) \n",
      "   - Happy     :  280 ( 38.3%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   - Neutral   :  287 ( 39.3%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   - Sad       :  133 ( 18.2%) ‚ñà‚ñà‚ñà\n",
      "\n",
      "üìã DISTRIBUZIONE CAMPIONI PER SESSIONE:\n",
      "   - Sessione 5:  731 (100.0%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      ‚îî‚îÄ Angry     :  31 (  4.2%)\n",
      "      ‚îî‚îÄ Happy     : 280 ( 38.3%)\n",
      "      ‚îî‚îÄ Neutral   : 287 ( 39.3%)\n",
      "      ‚îî‚îÄ Sad       : 133 ( 18.2%)\n",
      "------------------------------------------------------------\n",
      "‚úÖ Dataset initialized: 731 test samples\n",
      "\n",
      "================================================================================\n",
      "üì¶ DATALOADER SUMMARY - IEMOCAP\n",
      "================================================================================\n",
      "Train Dataloader:      53 batch √ó 32 samples = 1678 totali\n",
      "Validation Dataloader: 17 batch √ó 32 samples = 534 totali\n",
      "Test Dataloader:       23 batch √ó 32 samples = 731 totali\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "from dataset.custom_iemocap_dataset import CustomIEMOCAPDataset\n",
    "from utils.get_dataset_statistics import print_iemocap_stats\n",
    "print(\"=\"*80)\n",
    "print(\"üîÑ CREAZIONE DATASET E DATALOADER - IEMOCAP\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Verifica percorso\n",
    "if not iemocap_path or not Path(iemocap_path).exists():\n",
    "    raise ValueError(f\"‚ùå Dataset IEMOCAP non trovato in: {iemocap_path}\")\n",
    "\n",
    "print(f\"‚úÖ Usando dataset da: {iemocap_path}\\n\")\n",
    "\n",
    "# Crea i dataset\n",
    "train_iemocap_dataset = CustomIEMOCAPDataset(dataset_root=iemocap_path, split='train')\n",
    "val_iemocap_dataset = CustomIEMOCAPDataset(dataset_root=iemocap_path, split='validation')\n",
    "test_iemocap_dataset = CustomIEMOCAPDataset(dataset_root=iemocap_path, split='test')\n",
    "\n",
    "# Crea i dataloader\n",
    "batch_size = 32\n",
    "train_iemocap_dataloader = DataLoader(train_iemocap_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_iemocap_dataloader = DataLoader(val_iemocap_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_iemocap_dataloader = DataLoader(test_iemocap_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "# Riepilogo dataloader\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üì¶ DATALOADER SUMMARY - IEMOCAP\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Train Dataloader:      {len(train_iemocap_dataloader)} batch √ó {batch_size} samples = {len(train_iemocap_dataset)} totali\")\n",
    "print(f\"Validation Dataloader: {len(val_iemocap_dataloader)} batch √ó {batch_size} samples = {len(val_iemocap_dataset)} totali\")\n",
    "print(f\"Test Dataloader:       {len(test_iemocap_dataloader)} batch √ó {batch_size} samples = {len(test_iemocap_dataset)} totali\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Weights & Biases : Genera i grafici e compara gli esperimenti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "4-dxDQOFcdgX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "import os\n",
    "os.environ['WANDB_API_KEY'] = '7ade30086de7899bed412e3eb5c2da065c146f90'\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "8q9OvEDHxmRv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "‚úÖ RAVDESS trovato: data\\ravdess\n",
      "\n",
      "üìä Statistiche del dataset RAVDESS:\n",
      "\n",
      "========================================\n",
      "üìä ANALISI RAVDESS TRAINING SET\n",
      "========================================\n",
      "üîπ Samples Totali: 1440\n",
      "üîπ Attori (20): [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
      "   - Maschi:  10\n",
      "   - Femmine: 10\n",
      "\n",
      "üé≠ Distribuzione Emozioni:\n",
      "   - Angry     :  320 ( 22.2%) ‚ñà‚ñà‚ñà‚ñà\n",
      "   - Happy     :  320 ( 22.2%) ‚ñà‚ñà‚ñà‚ñà\n",
      "   - Neutral   :  480 ( 33.3%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   - Sad       :  320 ( 22.2%) ‚ñà‚ñà‚ñà‚ñà\n",
      "----------------------------------------\n",
      "üìä Statistiche del dataset RAVDESS:\n",
      "\n",
      "========================================\n",
      "üìä ANALISI RAVDESS VALIDATION SET\n",
      "========================================\n",
      "üîπ Samples Totali: 144\n",
      "üîπ Attori (2): [21, 22]\n",
      "   - Maschi:  1\n",
      "   - Femmine: 1\n",
      "\n",
      "üé≠ Distribuzione Emozioni:\n",
      "   - Angry     :   32 ( 22.2%) ‚ñà‚ñà‚ñà‚ñà\n",
      "   - Happy     :   32 ( 22.2%) ‚ñà‚ñà‚ñà‚ñà\n",
      "   - Neutral   :   48 ( 33.3%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   - Sad       :   32 ( 22.2%) ‚ñà‚ñà‚ñà‚ñà\n",
      "----------------------------------------\n",
      "Train samples: 1440\n",
      "Val samples: 144\n",
      "\n",
      "================================================================================\n",
      "üèóÔ∏è ARCHITETTURA DEL MODELLO\n",
      "================================================================================\n",
      "CRNN_BiLSTM(\n",
      "  (block1): Sequential(\n",
      "    (0): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout2d(p=0.2, inplace=False)\n",
      "    (4): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (block2): Sequential(\n",
      "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout2d(p=0.2, inplace=False)\n",
      "    (4): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (block3): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout2d(p=0.2, inplace=False)\n",
      "    (4): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (block4): Sequential(\n",
      "    (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout2d(p=0.2, inplace=False)\n",
      "    (4): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (projection): Linear(in_features=1024, out_features=128, bias=True)\n",
      "  (lstm): LSTM(128, 128, batch_first=True, bidirectional=True)\n",
      "  (attention_linear): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (classifier): Linear(in_features=256, out_features=4, bias=True)\n",
      ")\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üîß IPERPARAMETRI DI TRAINING\n",
      "================================================================================\n",
      "Device:                cuda\n",
      "Batch Size:            64\n",
      "Learning Rate:         0.0001\n",
      "Weight Decay (L2):     0.001\n",
      "Number of Epochs:      100\n",
      "Early Stopping Patience: 10\n",
      "\n",
      "Modello:\n",
      "  - Num Classes:       4\n",
      "  - Time Steps:        90\n",
      "  - Mel Bands:         128\n",
      "\n",
      "Optimizer:             Adam\n",
      "Loss Function:         CrossEntropyLoss\n",
      "Train Samples:         1440\n",
      "Val Samples:           144\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Epoch    Train Loss      Train Acc       Val Loss        Val Acc        \n",
      "================================================================================\n",
      "1        1.3611          22.85          % 1.3441          22.22          % ‚≠ê\n",
      "üìä Best val loss: 1.3441\n",
      "2        1.3434          22.99          % 1.3149          29.17          % ‚≠ê\n",
      "‚úì Migliorato! New best: 1.3149\n",
      "3        1.2988          32.50          % 1.2789          27.78          % \n",
      "‚úì Migliorato! New best: 1.2789\n",
      "4        1.2443          36.04          % 1.1857          37.50          % ‚≠ê\n",
      "‚úì Migliorato! New best: 1.1857\n",
      "5        1.1886          36.32          % 1.2543          27.78          % \n",
      "‚ö†Ô∏è Nessun miglioramento (1/10)\n",
      "6        1.1607          39.93          % 1.1028          37.50          % \n",
      "‚úì Migliorato! New best: 1.1028\n",
      "7        1.1320          44.10          % 1.0325          38.89          % ‚≠ê\n",
      "‚úì Migliorato! New best: 1.0325\n",
      "8        1.0967          43.47          % 1.2025          33.33          % \n",
      "‚ö†Ô∏è Nessun miglioramento (1/10)\n",
      "9        1.0800          46.53          % 1.0020          37.50          % \n",
      "‚úì Migliorato! New best: 1.0020\n",
      "10       1.0647          42.99          % 1.2020          27.78          % \n",
      "‚ö†Ô∏è Nessun miglioramento (1/10)\n",
      "11       1.0497          46.74          % 1.1535          31.94          % \n",
      "‚ö†Ô∏è Nessun miglioramento (2/10)\n",
      "12       1.0294          48.75          % 1.0560          33.33          % \n",
      "‚ö†Ô∏è Nessun miglioramento (3/10)\n",
      "13       1.0163          50.56          % 0.9746          37.50          % \n",
      "‚úì Migliorato! New best: 0.9746\n",
      "14       1.0018          50.00          % 0.9516          37.50          % \n",
      "‚úì Migliorato! New best: 0.9516\n",
      "15       0.9900          50.56          % 0.8486          48.61          % ‚≠ê\n",
      "‚úì Migliorato! New best: 0.8486\n",
      "16       0.9717          50.62          % 0.8467          45.83          % \n",
      "\n",
      "üîÑ SWA attivato dalla epoca 16\n",
      "\n",
      "‚úì Migliorato! New best: 0.8467\n",
      "17       0.9623          52.78          % 0.8642          43.06          % \n",
      "‚ö†Ô∏è Nessun miglioramento (1/10)\n",
      "18       0.9551          52.92          % 0.8095          59.72          % ‚≠ê\n",
      "‚úì Migliorato! New best: 0.8095\n",
      "19       0.9391          53.33          % 0.8307          59.72          % \n",
      "‚ö†Ô∏è Nessun miglioramento (1/10)\n",
      "20       0.9472          54.58          % 0.8294          55.56          % \n",
      "  SWA: 0.7878 loss | 58.33% acc\n",
      "‚ö†Ô∏è Nessun miglioramento (2/10)\n",
      "21       0.9376          56.74          % 0.7757          56.94          % \n",
      "‚úì Migliorato! New best: 0.7757\n",
      "22       0.9087          53.33          % 0.7810          61.11          % ‚≠ê\n",
      "‚ö†Ô∏è Nessun miglioramento (1/10)\n",
      "23       0.9033          55.42          % 0.8547          61.11          % \n",
      "‚ö†Ô∏è Nessun miglioramento (2/10)\n",
      "24       0.8905          58.19          % 0.8646          56.94          % \n",
      "‚ö†Ô∏è Nessun miglioramento (3/10)\n",
      "25       0.8888          56.88          % 0.7972          66.67          % ‚≠ê\n",
      "  SWA: 0.7741 loss | 58.33% acc\n",
      "‚ö†Ô∏è Nessun miglioramento (4/10)\n",
      "26       0.9012          58.75          % 0.7889          62.50          % \n",
      "‚ö†Ô∏è Nessun miglioramento (5/10)\n",
      "27       0.8826          56.67          % 0.7030          56.94          % \n",
      "‚úì Migliorato! New best: 0.7030\n",
      "28       0.8491          59.03          % 0.7318          61.11          % \n",
      "‚ö†Ô∏è Nessun miglioramento (1/10)\n",
      "29       0.8635          59.51          % 0.7002          62.50          % \n",
      "‚úì Migliorato! New best: 0.7002\n",
      "30       0.8728          57.78          % 0.7064          65.28          % \n",
      "  SWA: 0.7511 loss | 63.89% acc\n",
      "‚ö†Ô∏è Nessun miglioramento (1/10)\n",
      "31       0.8505          61.46          % 0.7870          62.50          % \n",
      "‚ö†Ô∏è Nessun miglioramento (2/10)\n",
      "32       0.8347          62.43          % 0.7400          59.72          % \n",
      "‚ö†Ô∏è Nessun miglioramento (3/10)\n",
      "33       0.8526          59.38          % 0.7541          58.33          % \n",
      "‚ö†Ô∏è Nessun miglioramento (4/10)\n",
      "34       0.8335          59.65          % 0.7888          65.28          % \n",
      "‚ö†Ô∏è Nessun miglioramento (5/10)\n",
      "35       0.8149          60.97          % 0.8504          65.28          % \n",
      "  SWA: 0.7459 loss | 62.50% acc\n",
      "‚ö†Ô∏è Nessun miglioramento (6/10)\n",
      "36       0.8332          60.14          % 0.7916          62.50          % \n",
      "‚ö†Ô∏è Nessun miglioramento (7/10)\n",
      "37       0.7970          63.89          % 0.7018          62.50          % \n",
      "‚ö†Ô∏è Nessun miglioramento (8/10)\n",
      "38       0.8026          62.92          % 0.7751          62.50          % \n",
      "‚ö†Ô∏è Nessun miglioramento (9/10)\n",
      "39       0.7786          65.42          % 0.7387          62.50          % \n",
      "‚ö†Ô∏è Nessun miglioramento (10/10)\n",
      "üõë STOP! Nessun miglioramento per 10 epoche\n",
      "\n",
      "‚èπÔ∏è Early stopping alla epoca 39\n",
      "================================================================================\n",
      "\n",
      "üîÑ Valutazione SWA finale...\n",
      "  Final SWA: 0.7400 loss | 62.50% acc\n",
      "\n",
      "================================================================================\n",
      "‚úÖ TRAINING COMPLETED\n",
      "================================================================================\n",
      "Best Validation Accuracy (Regular):  66.67%\n",
      "Best Validation Accuracy (SWA):      63.89%\n",
      "SWA Improvement:                     -2.78%\n",
      "\n",
      "üì¶ Recommended checkpoint: best_swa_model.pth\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: pagliarellomatteo (pagliarellomatteo-politecnico-di-torino) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n",
      "wandb: setting up run qklf0ifk\n",
      "wandb: Tracking run with wandb version 0.23.1\n",
      "wandb: Run data is saved locally in d:\\Roba da D\\Poli\\ML Vision\\speech-emotion-recognition-25\\wandb\\run-20260121_182422-qklf0ifk\n",
      "wandb: Run `wandb offline` to turn off syncing.\n",
      "wandb: Syncing run train_20260121_192422\n",
      "wandb:  View project at https://wandb.ai/pagliarellomatteo-politecnico-di-torino/speech-emotion-recognition\n",
      "wandb:  View run at https://wandb.ai/pagliarellomatteo-politecnico-di-torino/speech-emotion-recognition/runs/qklf0ifk\n",
      "d:\\Roba da D\\Poli\\ML Vision\\speech-emotion-recognition-25\\venv\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1141: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1480.)\n",
      "  result = _VF.lstm(\n",
      "wandb: updating run metadata\n",
      "wandb: uploading output.log; uploading wandb-summary.json; uploading config.yaml\n",
      "wandb: \n",
      "wandb: Run history:\n",
      "wandb:            epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà\n",
      "wandb: swa_val_accuracy ‚ñÅ‚ñÅ‚ñà‚ñÜ\n",
      "wandb:     swa_val_loss ‚ñà‚ñÜ‚ñÇ‚ñÅ\n",
      "wandb:   train_accuracy ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà\n",
      "wandb:       train_loss ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ\n",
      "wandb:     val_accuracy ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá\n",
      "wandb:         val_loss ‚ñà‚ñà‚ñá‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÅ\n",
      "wandb: \n",
      "wandb: Run summary:\n",
      "wandb:            epoch 39\n",
      "wandb: swa_val_accuracy 62.5\n",
      "wandb:     swa_val_loss 0.74585\n",
      "wandb:   train_accuracy 65.41667\n",
      "wandb:       train_loss 0.77863\n",
      "wandb:     val_accuracy 62.5\n",
      "wandb:         val_loss 0.73868\n",
      "wandb: \n",
      "wandb:  View run train_20260121_192422 at: https://wandb.ai/pagliarellomatteo-politecnico-di-torino/speech-emotion-recognition/runs/qklf0ifk\n",
      "wandb:  View project at: https://wandb.ai/pagliarellomatteo-politecnico-di-torino/speech-emotion-recognition\n",
      "wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "wandb: Find logs at: .\\wandb\\run-20260121_182422-qklf0ifk\\logs\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Esegui train.py dal project root\n",
    "result = subprocess.run(\n",
    "    [sys.executable, str(PROJECT_ROOT / 'ravdess_train' / 'train.py'), '--model', 'CRNN_BiLSTM'],\n",
    "    cwd=str(PROJECT_ROOT),\n",
    "    capture_output=False\n",
    ")\n",
    "\n",
    "#result = subprocess.run(\n",
    "#    [sys.executable, str(PROJECT_ROOT / 'ravdess_train' / 'train.py'), '--model', 'CRNN_BiGRU'],\n",
    "#    cwd=str(PROJECT_ROOT)\n",
    "#)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DyQo3klIymlz"
   },
   "source": [
    "# Step 5: Evaluate your model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9goKvp4jxk4j"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: pagliarellomatteo (pagliarellomatteo-politecnico-di-torino) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n",
      "wandb: setting up run egwxud5u\n",
      "wandb: Tracking run with wandb version 0.23.1\n",
      "wandb: Run data is saved locally in d:\\Roba da D\\Poli\\ML Vision\\speech-emotion-recognition-25\\wandb\\run-20260121_184105-egwxud5u\n",
      "wandb: Run `wandb offline` to turn off syncing.\n",
      "wandb: Syncing run eval_20260121_194104\n",
      "wandb:  View project at https://wandb.ai/pagliarellomatteo-politecnico-di-torino/speech-emotion-recognition\n",
      "wandb:  View run at https://wandb.ai/pagliarellomatteo-politecnico-di-torino/speech-emotion-recognition/runs/egwxud5u\n",
      "wandb: uploading artifact run-egwxud5u-classification_report; updating run metadata\n",
      "wandb: uploading artifact run-egwxud5u-classification_report; uploading config.yaml\n",
      "wandb: uploading artifact run-egwxud5u-classification_report\n",
      "wandb: \n",
      "wandb: Run history:\n",
      "wandb:    test_accuracy ‚ñÅ\n",
      "wandb:    test_macro_f1 ‚ñÅ\n",
      "wandb: test_weighted_f1 ‚ñÅ\n",
      "wandb: \n",
      "wandb: Run summary:\n",
      "wandb:    test_accuracy 0.48611\n",
      "wandb:    test_macro_f1 0.49351\n",
      "wandb: test_weighted_f1 0.50812\n",
      "wandb: \n",
      "wandb:  View run eval_20260121_194104 at: https://wandb.ai/pagliarellomatteo-politecnico-di-torino/speech-emotion-recognition/runs/egwxud5u\n",
      "wandb:  View project at: https://wandb.ai/pagliarellomatteo-politecnico-di-torino/speech-emotion-recognition\n",
      "wandb: Synced 5 W&B file(s), 2 media file(s), 2 artifact file(s) and 0 other file(s)\n",
      "wandb: Find logs at: .\\wandb\\run-20260121_184105-egwxud5u\\logs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Timestamp valutazione: 20260121_194104\n",
      "\n",
      "‚úÖ RAVDESS trovato: data\\ravdess\n",
      "\n",
      "Loading RAVDESS test set...\n",
      "üìä Statistiche del dataset RAVDESS:\n",
      "\n",
      "========================================\n",
      "üìä ANALISI RAVDESS TEST SET\n",
      "========================================\n",
      "üîπ Samples Totali: 144\n",
      "üîπ Attori (2): [23, 24]\n",
      "   - Maschi:  1\n",
      "   - Femmine: 1\n",
      "\n",
      "üé≠ Distribuzione Emozioni:\n",
      "   - Angry     :   32 ( 22.2%) ‚ñà‚ñà‚ñà‚ñà\n",
      "   - Happy     :   32 ( 22.2%) ‚ñà‚ñà‚ñà‚ñà\n",
      "   - Neutral   :   48 ( 33.3%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   - Sad       :   32 ( 22.2%) ‚ñà‚ñà‚ñà‚ñà\n",
      "----------------------------------------\n",
      "‚úÖ Test samples: 144\n",
      "\n",
      "Loading model...\n",
      "‚úÖ Modello caricato da checkpoints/best_model.pth\n",
      "\n",
      "================================================================================\n",
      "TESTING IN CORSO...\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "üìä METRICHE DI VALUTAZIONE - FASE 1 (RAVDESS BASELINE)\n",
      "================================================================================\n",
      "\n",
      "üéØ METRICHE PRINCIPALI:\n",
      "   ‚úÖ Accuracy:           48.61%\n",
      "   üìà Macro-Avg F1:       0.4935\n",
      "   üìä Weighted-Avg F1:    0.5081\n",
      "\n",
      "üìã CLASS DISTRIBUTION (Test Set):\n",
      "   neutral   :  48 samples ( 33.3%)\n",
      "   happy     :  32 samples ( 22.2%)\n",
      "   sad       :  32 samples ( 22.2%)\n",
      "   angry     :  32 samples ( 22.2%)\n",
      "\n",
      "üé≠ DETAILED CLASSIFICATION REPORT:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.62      0.62      0.62        48\n",
      "       happy       0.47      0.44      0.45        32\n",
      "         sad       0.17      0.25      0.21        32\n",
      "       angry       0.90      0.56      0.69        32\n",
      "\n",
      "    accuracy                           0.49       144\n",
      "   macro avg       0.54      0.47      0.49       144\n",
      "weighted avg       0.55      0.49      0.51       144\n",
      "\n",
      "Figure(1000x800)\n",
      "\n",
      "================================================================================\n",
      "‚úÖ Evaluation Complete!\n",
      "   Final Accuracy: 48.61%\n",
      "   Macro-Avg F1:   0.4935\n",
      "   Weighted-Avg F1: 0.5081\n",
      "   Risultati loggati su W&B\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Esegui eval.py dal project root\n",
    "checkpoint_path = PROJECT_ROOT / 'checkpoints' / 'best_model.pth'\n",
    "result = subprocess.run(\n",
    "    [sys.executable, str(PROJECT_ROOT / 'ravdess_train' / 'eval.py'), '--model', 'CRNN_BiLSTM', '--checkpoint', str(checkpoint_path)],\n",
    "    cwd=str(PROJECT_ROOT),\n",
    "    capture_output=False\n",
    ")\n",
    "\n",
    "#result = subprocess.run(\n",
    "#    [sys.executable, str(PROJECT_ROOT / 'ravdess_train' / 'eval.py'), '--model', 'CRNN_BiGRU', '--checkpoint', str(checkpoint_path)],\n",
    "#    cwd=str(PROJECT_ROOT)\n",
    "#)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
