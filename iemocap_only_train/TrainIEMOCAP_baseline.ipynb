{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bifSi62Ixrqr"
   },
   "source": [
    "# IEMOCAP Training Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch: 2.10.0+cu128\n",
      "Project Root: d:\\Roba da D\\Poli\\ML Vision\\speech-emotion-recognition-25\n",
      "Device: cuda (NVIDIA GeForce RTX 5060 Ti)\n"
     ]
    }
   ],
   "source": [
    "# Setup environment\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "NOTEBOOK_DIR = Path(os.getcwd())\n",
    "PROJECT_ROOT = NOTEBOOK_DIR.parent if NOTEBOOK_DIR.name == 'iemocap_only_train' else NOTEBOOK_DIR\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"Project Root: {PROJECT_ROOT}\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device} {'(' + torch.cuda.get_device_name(0) + ')' if torch.cuda.is_available() else ''}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Download IEMOCAP (locale) ---\n",
      "‚úì IEMOCAP gi√† presente: d:\\Roba da D\\Poli\\ML Vision\\speech-emotion-recognition-25\\data\\iemocap\n",
      "Numero di file: 81249\n",
      "‚úÖ IEMOCAP: d:\\Roba da D\\Poli\\ML Vision\\speech-emotion-recognition-25\\data\\iemocap\\IEMOCAP_full_release\n"
     ]
    }
   ],
   "source": [
    "# Download IEMOCAP dataset\n",
    "from utils.download_dataset_local import dowload_iemocap_local\n",
    "\n",
    "iemocap_path = dowload_iemocap_local()\n",
    "print(f\"‚úÖ IEMOCAP: {iemocap_path}\" if iemocap_path else \"‚ùå Download failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Caricate 5531 etichette\n",
      "üîç Raccogliendo campioni audio...\n",
      "‚úÖ Raccolti 2943 campioni audio validi\n",
      "   - Solo campioni improvvisati\n",
      "   - Emozioni: ['neutral', 'happy', 'sad', 'angry', 'happy']\n",
      "üìä Statistiche del dataset IEMOCAP:\n",
      "\n",
      "============================================================\n",
      "üìä ANALISI IEMOCAP TRAINING SET\n",
      "============================================================\n",
      "\n",
      "üîπ SAMPLES TOTALI: 1678\n",
      "üîπ SESSIONI: ['1', '2', '3']\n",
      "üîπ SPEAKER UNICI (session, gender): 6\n",
      "   Elenco: [('1', 'F'), ('1', 'M'), ('2', 'F'), ('2', 'M'), ('3', 'F'), ('3', 'M')]\n",
      "üîπ IMPROVVISAZIONI UNICHE: 12\n",
      "   Elenco: ['01', '02', '03', '04', '05', '05a', '05b', '06', '07', '08', '08a', '08b']\n",
      "\n",
      "üë• SPEAKER INDEPENDENCE (per verificare leakage):\n",
      "   - Sessione 1: (Ses1, F), (Ses1, M)\n",
      "   - Sessione 2: (Ses2, F), (Ses2, M)\n",
      "   - Sessione 3: (Ses3, F), (Ses3, M)\n",
      "\n",
      "üé≠ DISTRIBUZIONE EMOZIONI:\n",
      "   - Angry     :  174 ( 10.4%) ‚ñà‚ñà\n",
      "   - Happy     :  472 ( 28.1%) ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   - Neutral   :  638 ( 38.0%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   - Sad       :  394 ( 23.5%) ‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "üìã DISTRIBUZIONE CAMPIONI PER SESSIONE:\n",
      "   - Sessione 1:  521 ( 31.0%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      ‚îî‚îÄ Angry     :  62 ( 11.9%)\n",
      "      ‚îî‚îÄ Happy     : 132 ( 25.3%)\n",
      "      ‚îî‚îÄ Neutral   : 223 ( 42.8%)\n",
      "      ‚îî‚îÄ Sad       : 104 ( 20.0%)\n",
      "   - Sessione 2:  530 ( 31.6%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      ‚îî‚îÄ Angry     :  22 (  4.2%)\n",
      "      ‚îî‚îÄ Happy     : 191 ( 36.0%)\n",
      "      ‚îî‚îÄ Neutral   : 217 ( 40.9%)\n",
      "      ‚îî‚îÄ Sad       : 100 ( 18.9%)\n",
      "   - Sessione 3:  627 ( 37.4%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      ‚îî‚îÄ Angry     :  90 ( 14.4%)\n",
      "      ‚îî‚îÄ Happy     : 149 ( 23.8%)\n",
      "      ‚îî‚îÄ Neutral   : 198 ( 31.6%)\n",
      "      ‚îî‚îÄ Sad       : 190 ( 30.3%)\n",
      "------------------------------------------------------------\n",
      "‚úÖ Dataset initialized: 1678 train samples\n",
      "‚úÖ Caricate 5531 etichette\n",
      "üîç Raccogliendo campioni audio...\n",
      "‚úÖ Raccolti 2943 campioni audio validi\n",
      "   - Solo campioni improvvisati\n",
      "   - Emozioni: ['neutral', 'happy', 'sad', 'angry', 'happy']\n",
      "üìä Statistiche del dataset IEMOCAP:\n",
      "\n",
      "============================================================\n",
      "üìä ANALISI IEMOCAP VALIDATION SET\n",
      "============================================================\n",
      "\n",
      "üîπ SAMPLES TOTALI: 534\n",
      "üîπ SESSIONI: ['4']\n",
      "üîπ SPEAKER UNICI (session, gender): 2\n",
      "   Elenco: [('4', 'F'), ('4', 'M')]\n",
      "üîπ IMPROVVISAZIONI UNICHE: 8\n",
      "   Elenco: ['01', '02', '03', '04', '05', '06', '07', '08']\n",
      "\n",
      "üë• SPEAKER INDEPENDENCE (per verificare leakage):\n",
      "   - Sessione 4: (Ses4, F), (Ses4, M)\n",
      "\n",
      "üé≠ DISTRIBUZIONE EMOZIONI:\n",
      "   - Angry     :   84 ( 15.7%) ‚ñà‚ñà‚ñà\n",
      "   - Happy     :  195 ( 36.5%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   - Neutral   :  174 ( 32.6%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   - Sad       :   81 ( 15.2%) ‚ñà‚ñà‚ñà\n",
      "\n",
      "üìã DISTRIBUZIONE CAMPIONI PER SESSIONE:\n",
      "   - Sessione 4:  534 (100.0%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      ‚îî‚îÄ Angry     :  84 ( 15.7%)\n",
      "      ‚îî‚îÄ Happy     : 195 ( 36.5%)\n",
      "      ‚îî‚îÄ Neutral   : 174 ( 32.6%)\n",
      "      ‚îî‚îÄ Sad       :  81 ( 15.2%)\n",
      "------------------------------------------------------------\n",
      "‚úÖ Dataset initialized: 534 validation samples\n",
      "‚úÖ Caricate 5531 etichette\n",
      "üîç Raccogliendo campioni audio...\n",
      "‚úÖ Raccolti 2943 campioni audio validi\n",
      "   - Solo campioni improvvisati\n",
      "   - Emozioni: ['neutral', 'happy', 'sad', 'angry', 'happy']\n",
      "üìä Statistiche del dataset IEMOCAP:\n",
      "\n",
      "============================================================\n",
      "üìä ANALISI IEMOCAP TEST SET\n",
      "============================================================\n",
      "\n",
      "üîπ SAMPLES TOTALI: 731\n",
      "üîπ SESSIONI: ['5']\n",
      "üîπ SPEAKER UNICI (session, gender): 2\n",
      "   Elenco: [('5', 'F'), ('5', 'M')]\n",
      "üîπ IMPROVVISAZIONI UNICHE: 8\n",
      "   Elenco: ['01', '02', '03', '04', '05', '06', '07', '08']\n",
      "\n",
      "üë• SPEAKER INDEPENDENCE (per verificare leakage):\n",
      "   - Sessione 5: (Ses5, F), (Ses5, M)\n",
      "\n",
      "üé≠ DISTRIBUZIONE EMOZIONI:\n",
      "   - Angry     :   31 (  4.2%) \n",
      "   - Happy     :  280 ( 38.3%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   - Neutral   :  287 ( 39.3%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   - Sad       :  133 ( 18.2%) ‚ñà‚ñà‚ñà\n",
      "\n",
      "üìã DISTRIBUZIONE CAMPIONI PER SESSIONE:\n",
      "   - Sessione 5:  731 (100.0%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      ‚îî‚îÄ Angry     :  31 (  4.2%)\n",
      "      ‚îî‚îÄ Happy     : 280 ( 38.3%)\n",
      "      ‚îî‚îÄ Neutral   : 287 ( 39.3%)\n",
      "      ‚îî‚îÄ Sad       : 133 ( 18.2%)\n",
      "------------------------------------------------------------\n",
      "‚úÖ Dataset initialized: 731 test samples\n",
      "Train: 1678 | Val: 534 | Test: 731\n"
     ]
    }
   ],
   "source": [
    "# Create IEMOCAP DataLoaders\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset.custom_iemocap_dataset import CustomIEMOCAPDataset\n",
    "\n",
    "train_dataset = CustomIEMOCAPDataset(dataset_root=iemocap_path, split='train', spec_freq_mask=30, spec_time_mask=15)\n",
    "val_dataset = CustomIEMOCAPDataset(dataset_root=iemocap_path, split='validation')\n",
    "test_dataset = CustomIEMOCAPDataset(dataset_root=iemocap_path, split='test')\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Train: {len(train_dataset)} | Val: {len(val_dataset)} | Test: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "4-dxDQOFcdgX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# W&B Login\n",
    "import wandb\n",
    "import os\n",
    "os.environ['WANDB_API_KEY'] = '7ade30086de7899bed412e3eb5c2da065c146f90'\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "id": "8q9OvEDHxmRv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Roba da D\\Poli\\ML Vision\\speech-emotion-recognition-25\\iemocap_only_train\n",
      "Using device: cuda\n",
      "\n",
      "‚úÖ IEMOCAP trovato: d:\\Roba da D\\Poli\\ML Vision\\speech-emotion-recognition-25\\data\\iemocap\\IEMOCAP_full_release\n",
      "\n",
      "‚úÖ Caricate 5531 etichette\n",
      "üîç Raccogliendo campioni audio...\n",
      "‚úÖ Raccolti 2943 campioni audio validi\n",
      "   - Solo campioni improvvisati\n",
      "   - Emozioni: ['neutral', 'happy', 'sad', 'angry', 'happy']\n",
      "üìä Statistiche del dataset IEMOCAP:\n",
      "\n",
      "============================================================\n",
      "üìä ANALISI IEMOCAP TRAINING SET\n",
      "============================================================\n",
      "\n",
      "üîπ SAMPLES TOTALI: 1678\n",
      "üîπ SESSIONI: ['1', '2', '3']\n",
      "üîπ SPEAKER UNICI (session, gender): 6\n",
      "   Elenco: [('1', 'F'), ('1', 'M'), ('2', 'F'), ('2', 'M'), ('3', 'F'), ('3', 'M')]\n",
      "üîπ IMPROVVISAZIONI UNICHE: 12\n",
      "   Elenco: ['01', '02', '03', '04', '05', '05a', '05b', '06', '07', '08', '08a', '08b']\n",
      "\n",
      "üë• SPEAKER INDEPENDENCE (per verificare leakage):\n",
      "   - Sessione 1: (Ses1, F), (Ses1, M)\n",
      "   - Sessione 2: (Ses2, F), (Ses2, M)\n",
      "   - Sessione 3: (Ses3, F), (Ses3, M)\n",
      "\n",
      "üé≠ DISTRIBUZIONE EMOZIONI:\n",
      "   - Angry     :  174 ( 10.4%) ‚ñà‚ñà\n",
      "   - Happy     :  472 ( 28.1%) ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   - Neutral   :  638 ( 38.0%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   - Sad       :  394 ( 23.5%) ‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "üìã DISTRIBUZIONE CAMPIONI PER SESSIONE:\n",
      "   - Sessione 1:  521 ( 31.0%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      ‚îî‚îÄ Angry     :  62 ( 11.9%)\n",
      "      ‚îî‚îÄ Happy     : 132 ( 25.3%)\n",
      "      ‚îî‚îÄ Neutral   : 223 ( 42.8%)\n",
      "      ‚îî‚îÄ Sad       : 104 ( 20.0%)\n",
      "   - Sessione 2:  530 ( 31.6%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      ‚îî‚îÄ Angry     :  22 (  4.2%)\n",
      "      ‚îî‚îÄ Happy     : 191 ( 36.0%)\n",
      "      ‚îî‚îÄ Neutral   : 217 ( 40.9%)\n",
      "      ‚îî‚îÄ Sad       : 100 ( 18.9%)\n",
      "   - Sessione 3:  627 ( 37.4%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      ‚îî‚îÄ Angry     :  90 ( 14.4%)\n",
      "      ‚îî‚îÄ Happy     : 149 ( 23.8%)\n",
      "      ‚îî‚îÄ Neutral   : 198 ( 31.6%)\n",
      "      ‚îî‚îÄ Sad       : 190 ( 30.3%)\n",
      "------------------------------------------------------------\n",
      "‚úÖ Dataset initialized: 1678 train samples\n",
      "‚úÖ Caricate 5531 etichette\n",
      "üîç Raccogliendo campioni audio...\n",
      "‚úÖ Raccolti 2943 campioni audio validi\n",
      "   - Solo campioni improvvisati\n",
      "   - Emozioni: ['neutral', 'happy', 'sad', 'angry', 'happy']\n",
      "üìä Statistiche del dataset IEMOCAP:\n",
      "\n",
      "============================================================\n",
      "üìä ANALISI IEMOCAP VALIDATION SET\n",
      "============================================================\n",
      "\n",
      "üîπ SAMPLES TOTALI: 534\n",
      "üîπ SESSIONI: ['4']\n",
      "üîπ SPEAKER UNICI (session, gender): 2\n",
      "   Elenco: [('4', 'F'), ('4', 'M')]\n",
      "üîπ IMPROVVISAZIONI UNICHE: 8\n",
      "   Elenco: ['01', '02', '03', '04', '05', '06', '07', '08']\n",
      "\n",
      "üë• SPEAKER INDEPENDENCE (per verificare leakage):\n",
      "   - Sessione 4: (Ses4, F), (Ses4, M)\n",
      "\n",
      "üé≠ DISTRIBUZIONE EMOZIONI:\n",
      "   - Angry     :   84 ( 15.7%) ‚ñà‚ñà‚ñà\n",
      "   - Happy     :  195 ( 36.5%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   - Neutral   :  174 ( 32.6%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   - Sad       :   81 ( 15.2%) ‚ñà‚ñà‚ñà\n",
      "\n",
      "üìã DISTRIBUZIONE CAMPIONI PER SESSIONE:\n",
      "   - Sessione 4:  534 (100.0%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      ‚îî‚îÄ Angry     :  84 ( 15.7%)\n",
      "      ‚îî‚îÄ Happy     : 195 ( 36.5%)\n",
      "      ‚îî‚îÄ Neutral   : 174 ( 32.6%)\n",
      "      ‚îî‚îÄ Sad       :  81 ( 15.2%)\n",
      "------------------------------------------------------------\n",
      "‚úÖ Dataset initialized: 534 validation samples\n",
      "Train samples: 1678\n",
      "Val samples: 534\n",
      "\n",
      "================================================================================\n",
      "üèóÔ∏è ARCHITETTURA DEL MODELLO\n",
      "================================================================================\n",
      "CRNN_BiLSTM(\n",
      "  (block1): Sequential(\n",
      "    (0): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout2d(p=0.2, inplace=False)\n",
      "    (4): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (block2): Sequential(\n",
      "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout2d(p=0.2, inplace=False)\n",
      "    (4): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (block3): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout2d(p=0.2, inplace=False)\n",
      "    (4): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (block4): Sequential(\n",
      "    (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout2d(p=0.2, inplace=False)\n",
      "    (4): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (projection): Linear(in_features=1024, out_features=128, bias=True)\n",
      "  (lstm): LSTM(128, 128, batch_first=True, bidirectional=True)\n",
      "  (attention_linear): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (classifier): Linear(in_features=256, out_features=4, bias=True)\n",
      ")\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üîß IPERPARAMETRI DI TRAINING\n",
      "================================================================================\n",
      "Device:                cuda\n",
      "Batch Size:            64\n",
      "Learning Rate:         0.0001\n",
      "Weight Decay (L2):     0.001\n",
      "Number of Epochs:      100\n",
      "Early Stopping Patience: 10\n",
      "\n",
      "Modello:\n",
      "  - Num Classes:       4\n",
      "  - Time Steps:        90\n",
      "  - Mel Bands:         128\n",
      "\n",
      "Optimizer:             Adam\n",
      "Loss Function:         CrossEntropyLoss\n",
      "Train Samples:         1678\n",
      "Val Samples:           534\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Epoch    Train Loss      Train Acc       Val Loss        Val Acc        \n",
      "================================================================================\n",
      "1        1.3736          32.18          % 1.3760          32.58          % ‚≠ê\n",
      "üìä Best val loss: 1.3760\n",
      "2        1.3251          39.93          % 1.3231          37.83          % ‚≠ê\n",
      "‚úì Migliorato! New best: 1.3231\n",
      "3        1.2103          44.93          % 1.2662          35.02          % \n",
      "‚úì Migliorato! New best: 1.2662\n",
      "4        1.0859          46.90          % 1.1112          47.94          % ‚≠ê\n",
      "‚úì Migliorato! New best: 1.1112\n",
      "5        1.0082          50.18          % 1.0404          42.70          % \n",
      "‚úì Migliorato! New best: 1.0404\n",
      "6        1.0053          50.06          % 1.0180          48.31          % ‚≠ê\n",
      "‚úì Migliorato! New best: 1.0180\n",
      "7        0.9583          53.64          % 1.0338          42.88          % \n",
      "‚ö†Ô∏è Nessun miglioramento (1/10)\n",
      "8        0.9535          52.32          % 1.0087          45.32          % \n",
      "‚úì Migliorato! New best: 1.0087\n",
      "9        0.9371          56.44          % 1.0046          45.51          % \n",
      "‚úì Migliorato! New best: 1.0046\n",
      "10       0.9299          53.69          % 1.0120          45.88          % \n",
      "‚ö†Ô∏è Nessun miglioramento (1/10)\n",
      "11       0.9251          56.97          % 1.0008          47.38          % \n",
      "‚úì Migliorato! New best: 1.0008\n",
      "12       0.9202          57.51          % 0.9878          48.50          % ‚≠ê\n",
      "‚úì Migliorato! New best: 0.9878\n",
      "13       0.9249          56.73          % 0.9932          52.25          % ‚≠ê\n",
      "‚ö†Ô∏è Nessun miglioramento (1/10)\n",
      "14       0.9018          57.51          % 0.9884          51.50          % \n",
      "‚ö†Ô∏è Nessun miglioramento (2/10)\n",
      "15       0.9048          57.33          % 0.9938          47.75          % \n",
      "‚ö†Ô∏è Nessun miglioramento (3/10)\n",
      "16       0.9139          55.78          % 1.0216          42.32          % \n",
      "\n",
      "üîÑ SWA attivato dalla epoca 16\n",
      "\n",
      "‚ö†Ô∏è Nessun miglioramento (4/10)\n",
      "17       0.9087          58.40          % 1.0352          41.01          % \n",
      "‚ö†Ô∏è Nessun miglioramento (5/10)\n",
      "18       0.8860          56.62          % 0.9873          54.49          % ‚≠ê\n",
      "‚úì Migliorato! New best: 0.9873\n",
      "19       0.8667          60.37          % 1.0073          47.19          % \n",
      "‚ö†Ô∏è Nessun miglioramento (1/10)\n",
      "20       0.8559          59.30          % 0.9951          48.13          % \n",
      "  SWA: 1.0107 loss | 44.01% acc\n",
      "‚ö†Ô∏è Nessun miglioramento (2/10)\n",
      "21       0.8635          58.64          % 1.0001          50.94          % \n",
      "‚ö†Ô∏è Nessun miglioramento (3/10)\n",
      "22       0.9013          57.39          % 1.0849          41.01          % \n",
      "‚ö†Ô∏è Nessun miglioramento (4/10)\n",
      "23       0.9049          58.22          % 0.9793          48.88          % \n",
      "‚úì Migliorato! New best: 0.9793\n",
      "24       0.8385          58.82          % 0.9996          46.63          % \n",
      "‚ö†Ô∏è Nessun miglioramento (1/10)\n",
      "25       0.8553          58.05          % 0.9709          50.75          % \n",
      "  SWA: 1.0032 loss | 46.07% acc\n",
      "‚úì Migliorato! New best: 0.9709\n",
      "26       0.8289          61.14          % 1.0178          48.88          % \n",
      "‚ö†Ô∏è Nessun miglioramento (1/10)\n",
      "27       0.8605          59.54          % 0.9745          53.75          % \n",
      "‚ö†Ô∏è Nessun miglioramento (2/10)\n",
      "28       0.8308          60.13          % 0.9849          51.69          % \n",
      "‚ö†Ô∏è Nessun miglioramento (3/10)\n",
      "29       0.8384          62.81          % 1.0351          46.25          % \n",
      "‚ö†Ô∏è Nessun miglioramento (4/10)\n",
      "30       0.8408          61.38          % 1.0341          44.38          % \n",
      "  SWA: 1.0007 loss | 47.19% acc\n",
      "‚ö†Ô∏è Nessun miglioramento (5/10)\n",
      "31       0.8084          61.68          % 0.9739          50.37          % \n",
      "‚ö†Ô∏è Nessun miglioramento (6/10)\n",
      "32       0.8249          62.10          % 1.0848          39.51          % \n",
      "‚ö†Ô∏è Nessun miglioramento (7/10)\n",
      "33       0.7995          62.46          % 1.0220          49.25          % \n",
      "‚ö†Ô∏è Nessun miglioramento (8/10)\n",
      "34       0.7987          63.83          % 1.0838          41.01          % \n",
      "‚ö†Ô∏è Nessun miglioramento (9/10)\n",
      "35       0.7917          64.72          % 1.0343          44.19          % \n",
      "  SWA: 1.0060 loss | 47.57% acc\n",
      "‚ö†Ô∏è Nessun miglioramento (10/10)\n",
      "üõë STOP! Nessun miglioramento per 10 epoche\n",
      "\n",
      "‚èπÔ∏è Early stopping alla epoca 35\n",
      "================================================================================\n",
      "\n",
      "üîÑ Valutazione SWA finale...\n",
      "  Final SWA: 1.0051 loss | 47.57% acc\n",
      "\n",
      "================================================================================\n",
      "‚úÖ TRAINING COMPLETED\n",
      "================================================================================\n",
      "Best Validation Accuracy (Regular):  54.49%\n",
      "Best Validation Accuracy (SWA):      47.57%\n",
      "SWA Improvement:                     -6.93%\n",
      "\n",
      "üì¶ Recommended checkpoint: best_swa_model_iemocap_only.pth\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: pagliarellomatteo (pagliarellomatteo-politecnico-di-torino) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n",
      "wandb: setting up run xa80iz5j\n",
      "wandb: Tracking run with wandb version 0.23.1\n",
      "wandb: Run data is saved locally in d:\\Roba da D\\Poli\\ML Vision\\speech-emotion-recognition-25\\iemocap_only_train\\wandb\\run-20260124_153517-xa80iz5j\n",
      "wandb: Run `wandb offline` to turn off syncing.\n",
      "wandb: Syncing run train_20260124_163516\n",
      "wandb:  View project at https://wandb.ai/pagliarellomatteo-politecnico-di-torino/speech-emotion-recognition\n",
      "wandb:  View run at https://wandb.ai/pagliarellomatteo-politecnico-di-torino/speech-emotion-recognition/runs/xa80iz5j\n",
      "d:\\Roba da D\\Poli\\ML Vision\\speech-emotion-recognition-25\\venv\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1141: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1480.)\n",
      "  result = _VF.lstm(\n",
      "wandb: updating run metadata\n",
      "wandb: uploading output.log; uploading wandb-summary.json\n",
      "wandb: \n",
      "wandb: Run history:\n",
      "wandb:            epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà\n",
      "wandb: swa_val_accuracy ‚ñÅ‚ñÖ‚ñá‚ñà\n",
      "wandb:     swa_val_loss ‚ñà‚ñÉ‚ñÅ‚ñÖ\n",
      "wandb:   train_accuracy ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà\n",
      "wandb:       train_loss ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "wandb:     val_accuracy ‚ñÅ‚ñÉ‚ñÇ‚ñÜ‚ñÑ‚ñÜ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñà‚ñÜ‚ñÜ‚ñá‚ñÑ‚ñÜ‚ñÖ‚ñá‚ñÜ‚ñà‚ñá‚ñÖ‚ñÖ‚ñá‚ñÉ‚ñÜ‚ñÑ‚ñÖ\n",
      "wandb:         val_loss ‚ñà‚ñá‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÉ‚ñÇ\n",
      "wandb: \n",
      "wandb: Run summary:\n",
      "wandb:            epoch 35\n",
      "wandb: swa_val_accuracy 47.56554\n",
      "wandb:     swa_val_loss 1.00595\n",
      "wandb:   train_accuracy 64.7199\n",
      "wandb:       train_loss 0.79174\n",
      "wandb:     val_accuracy 44.19476\n",
      "wandb:         val_loss 1.03434\n",
      "wandb: \n",
      "wandb:  View run train_20260124_163516 at: https://wandb.ai/pagliarellomatteo-politecnico-di-torino/speech-emotion-recognition/runs/xa80iz5j\n",
      "wandb:  View project at: https://wandb.ai/pagliarellomatteo-politecnico-di-torino/speech-emotion-recognition\n",
      "wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "wandb: Find logs at: .\\wandb\\run-20260124_153517-xa80iz5j\\logs\n"
     ]
    }
   ],
   "source": [
    "#start training\n",
    "%cd {PROJECT_ROOT}/iemocap_only_train\n",
    "!python train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "9goKvp4jxk4j"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Roba da D\\Poli\\ML Vision\\speech-emotion-recognition-25\\iemocap_only_train\n",
      "Using device: cuda\n",
      "\n",
      "Timestamp valutazione: 20260124_164020\n",
      "\n",
      "‚úÖ IEMOCAP trovato: d:\\Roba da D\\Poli\\ML Vision\\speech-emotion-recognition-25\\data\\iemocap\\IEMOCAP_full_release\n",
      "\n",
      "Loading IEMOCAP test set...\n",
      "‚úÖ Caricate 5531 etichette\n",
      "üîç Raccogliendo campioni audio...\n",
      "‚úÖ Raccolti 2943 campioni audio validi\n",
      "   - Solo campioni improvvisati\n",
      "   - Emozioni: ['neutral', 'happy', 'sad', 'angry', 'happy']\n",
      "üìä Statistiche del dataset IEMOCAP:\n",
      "\n",
      "============================================================\n",
      "üìä ANALISI IEMOCAP TEST SET\n",
      "============================================================\n",
      "\n",
      "üîπ SAMPLES TOTALI: 731\n",
      "üîπ SESSIONI: ['5']\n",
      "üîπ SPEAKER UNICI (session, gender): 2\n",
      "   Elenco: [('5', 'F'), ('5', 'M')]\n",
      "üîπ IMPROVVISAZIONI UNICHE: 8\n",
      "   Elenco: ['01', '02', '03', '04', '05', '06', '07', '08']\n",
      "\n",
      "üë• SPEAKER INDEPENDENCE (per verificare leakage):\n",
      "   - Sessione 5: (Ses5, F), (Ses5, M)\n",
      "\n",
      "üé≠ DISTRIBUZIONE EMOZIONI:\n",
      "   - Angry     :   31 (  4.2%) \n",
      "   - Happy     :  280 ( 38.3%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   - Neutral   :  287 ( 39.3%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   - Sad       :  133 ( 18.2%) ‚ñà‚ñà‚ñà\n",
      "\n",
      "üìã DISTRIBUZIONE CAMPIONI PER SESSIONE:\n",
      "   - Sessione 5:  731 (100.0%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      ‚îî‚îÄ Angry     :  31 (  4.2%)\n",
      "      ‚îî‚îÄ Happy     : 280 ( 38.3%)\n",
      "      ‚îî‚îÄ Neutral   : 287 ( 39.3%)\n",
      "      ‚îî‚îÄ Sad       : 133 ( 18.2%)\n",
      "------------------------------------------------------------\n",
      "‚úÖ Dataset initialized: 731 test samples\n",
      "‚úÖ Test samples: 731\n",
      "\n",
      "Loading model...\n",
      "‚úÖ Modello caricato da d:\\Roba da D\\Poli\\ML Vision\\speech-emotion-recognition-25\\checkpoints\\iemocap_only\\best_model.pth\n",
      "\n",
      "================================================================================\n",
      "TESTING IN CORSO...\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "üìä METRICHE DI VALUTAZIONE - IEMOCAP\n",
      "================================================================================\n",
      "\n",
      "üéØ METRICHE PRINCIPALI:\n",
      "   ‚úÖ Accuracy:           53.49%\n",
      "   üìà Macro-Avg F1:       0.4639\n",
      "   üìä Weighted-Avg F1:    0.5224\n",
      "\n",
      "üìã CLASS DISTRIBUTION (Test Set):\n",
      "   neutral   : 287 samples ( 39.3%)\n",
      "   happy     : 280 samples ( 38.3%)\n",
      "   sad       : 133 samples ( 18.2%)\n",
      "   angry     :  31 samples (  4.2%)\n",
      "\n",
      "üé≠ DETAILED CLASSIFICATION REPORT:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.51      0.76      0.61       287\n",
      "       happy       0.60      0.34      0.43       280\n",
      "         sad       0.68      0.52      0.59       133\n",
      "       angry       0.20      0.26      0.22        31\n",
      "\n",
      "    accuracy                           0.53       731\n",
      "   macro avg       0.50      0.47      0.46       731\n",
      "weighted avg       0.56      0.53      0.52       731\n",
      "\n",
      "Figure(1000x800)\n",
      "\n",
      "================================================================================\n",
      "‚úÖ Evaluation Complete!\n",
      "   Final Accuracy: 53.49%\n",
      "   Macro-Avg F1:   0.4639\n",
      "   Weighted-Avg F1: 0.5224\n",
      "   Risultati loggati su W&B\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: pagliarellomatteo (pagliarellomatteo-politecnico-di-torino) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n",
      "wandb: Tracking run with wandb version 0.23.1\n",
      "wandb: Run data is saved locally in d:\\Roba da D\\Poli\\ML Vision\\speech-emotion-recognition-25\\iemocap_only_train\\wandb\\run-20260124_154020-jd0lnv2w\n",
      "wandb: Run `wandb offline` to turn off syncing.\n",
      "wandb: Syncing run eval_20260124_164020\n",
      "wandb:  View project at https://wandb.ai/pagliarellomatteo-politecnico-di-torino/speech-emotion-recognition\n",
      "wandb:  View run at https://wandb.ai/pagliarellomatteo-politecnico-di-torino/speech-emotion-recognition/runs/jd0lnv2w\n",
      "wandb: uploading artifact run-jd0lnv2w-classification_report; updating run metadata\n",
      "wandb: uploading artifact run-jd0lnv2w-classification_report; uploading config.yaml\n",
      "wandb: uploading artifact run-jd0lnv2w-classification_report\n",
      "wandb: uploading history steps 0-1, summary, console lines 0-82\n",
      "wandb: \n",
      "wandb: Run history:\n",
      "wandb:    test_accuracy ‚ñÅ\n",
      "wandb:    test_macro_f1 ‚ñÅ\n",
      "wandb: test_weighted_f1 ‚ñÅ\n",
      "wandb: \n",
      "wandb: Run summary:\n",
      "wandb:    test_accuracy 0.53488\n",
      "wandb:    test_macro_f1 0.46395\n",
      "wandb: test_weighted_f1 0.52239\n",
      "wandb: \n",
      "wandb:  View run eval_20260124_164020 at: https://wandb.ai/pagliarellomatteo-politecnico-di-torino/speech-emotion-recognition/runs/jd0lnv2w\n",
      "wandb:  View project at: https://wandb.ai/pagliarellomatteo-politecnico-di-torino/speech-emotion-recognition\n",
      "wandb: Synced 5 W&B file(s), 2 media file(s), 2 artifact file(s) and 0 other file(s)\n",
      "wandb: Find logs at: .\\wandb\\run-20260124_154020-jd0lnv2w\\logs\n"
     ]
    }
   ],
   "source": [
    "#start evaluation\n",
    "%cd {PROJECT_ROOT}/iemocap_only_train\n",
    "!python eval.py"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
