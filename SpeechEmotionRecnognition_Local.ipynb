{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bifSi62Ixrqr"
   },
   "source": [
    "# Step 3: Dataset Setup\n",
    "## Different options\n",
    "- First one is downloading using a script that places the data in the download folder (usually recommended)\n",
    "- Second one is uploading the dataset to your personal/institutional Google Drive and load it from there ([Read More](https://saturncloud.io/blog/google-colab-how-to-read-data-from-my-google-drive/))\n",
    "- Place the download script directly here on colab\n",
    "\n",
    "You are free to do as you please in this phase.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all required libraries\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "\n",
    "# Print system and environment info\n",
    "print(\"=\"*80)\n",
    "print(\"üîß PROJECT ENVIRONMENT INFO\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Python Version: {sys.version.split()[0]}\")\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"NumPy Version: {np.__version__}\")\n",
    "print(f\"Current Working Directory: {os.getcwd()}\")\n",
    "print()\n",
    "\n",
    "# Check CUDA availability\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úÖ CUDA is AVAILABLE\")\n",
    "    print(f\"   GPU Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   CUDA Version: {torch.version.cuda}\")\n",
    "    print(f\"   Number of GPUs: {torch.cuda.device_count()}\")\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    print(f\"‚ùå CUDA is NOT available - Using CPU\")\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(f\"   Default Device: {device}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DiWQTaTbxeIc"
   },
   "outputs": [],
   "source": [
    "from utils.download_dataset_local import dowload_ravdess_local\n",
    "\n",
    "dataset_path = dowload_ravdess_local()\n",
    "if dataset_path:\n",
    "    print(f\"‚úÖ Downloaded RAVDESS dataset locally in {dataset_path}...\")\n",
    "else:\n",
    "    print(\"‚ùå RAVDESS dataset download failed.\")\n",
    "    \n",
    "ravdess_path = dataset_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from dataset.custom_ravdess_dataset import CustomRAVDESSDataset\n",
    "from utils.get_dataset_statistics import print_dataset_stats\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üîÑ CREAZIONE DATASET E DATALOADER - RAVDESS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Verifica percorso\n",
    "if not ravdess_path or not Path(ravdess_path).exists():\n",
    "    raise ValueError(f\"‚ùå Dataset RAVDESS non trovato in: {ravdess_path}\")\n",
    "\n",
    "print(f\"‚úÖ Usando dataset da: {ravdess_path}\\n\")\n",
    "\n",
    "# Crea i dataset\n",
    "train_dataset = CustomRAVDESSDataset(dataset_root=ravdess_path, split='train')\n",
    "val_dataset = CustomRAVDESSDataset(dataset_root=ravdess_path, split='validation')\n",
    "test_dataset = CustomRAVDESSDataset(dataset_root=ravdess_path, split='test')\n",
    "\n",
    "# Crea i dataloader\n",
    "batch_size = 32\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "# Riepilogo dataloader\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üì¶ DATALOADER SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Train Dataloader:      {len(train_dataloader)} batch √ó {batch_size} samples = {len(train_dataset)} totali\")\n",
    "print(f\"Validation Dataloader: {len(val_dataloader)} batch √ó {batch_size} samples = {len(val_dataset)} totali\")\n",
    "print(f\"Test Dataloader:       {len(test_dataloader)} batch √ó {batch_size} samples = {len(test_dataset)} totali\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ricarica il modulo per usare la versione fixata\n",
    "import importlib\n",
    "import sys\n",
    "if 'utils.download_dataset_local' in sys.modules:\n",
    "    importlib.reload(sys.modules['utils.download_dataset_local'])\n",
    "\n",
    "from utils.download_dataset_local import dowload_iemocap_local\n",
    "\n",
    "iemocap_dataset_path = dowload_iemocap_local()\n",
    "if iemocap_dataset_path:\n",
    "    print(f\"‚úÖ Downloaded IEMOCAP dataset locally in {iemocap_dataset_path}...\")\n",
    "else:\n",
    "    print(\"‚ùå IEMOCAP dataset download failed.\")\n",
    "    \n",
    "iemocap_path = iemocap_dataset_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG: Verifica percorsi IEMOCAP\n",
    "print(\"=\"*80)\n",
    "print(\"üîç DEBUG - VERIFICA PERCORSI IEMOCAP\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "iemocap_debug_path = iemocap_path\n",
    "print(f\"1Ô∏è‚É£  Percorso passato: {iemocap_debug_path}\\n\")\n",
    "\n",
    "# Controlla se il percorso esiste\n",
    "print(f\"2Ô∏è‚É£  Percorso esiste: {Path(iemocap_debug_path).exists()}\\n\")\n",
    "\n",
    "# Lista cosa c'√® dentro\n",
    "if Path(iemocap_debug_path).exists():\n",
    "    print(f\"3Ô∏è‚É£  Contenuto di {iemocap_debug_path}:\")\n",
    "    for item in Path(iemocap_debug_path).iterdir():\n",
    "        print(f\"   - {item.name} {'(DIR)' if item.is_dir() else ''}\")\n",
    "    print()\n",
    "\n",
    "# Cerca le cartelle Session\n",
    "print(f\"4Ô∏è‚É£  Ricerca cartelle Session:\")\n",
    "session_folders = list(Path(iemocap_debug_path).glob(\"Session*\"))\n",
    "print(f\"   Trovate: {len(session_folders)} cartelle Session\")\n",
    "for s in session_folders[:3]:\n",
    "    print(f\"   - {s.name}\")\n",
    "print()\n",
    "\n",
    "# Se ci sono Session, controlla la struttura di una\n",
    "if session_folders:\n",
    "    session1 = session_folders[0]\n",
    "    print(f\"5Ô∏è‚É£  Dentro {session1.name}:\")\n",
    "    for item in (session1).iterdir():\n",
    "        print(f\"   - {item.name}\")\n",
    "    print()\n",
    "    \n",
    "    # Controlla wav folder\n",
    "    wav_path = session1 / \"sentences\" / \"wav\"\n",
    "    print(f\"6Ô∏è‚É£  Percorso wav: {wav_path}\")\n",
    "    print(f\"   Esiste: {wav_path.exists()}\")\n",
    "    if wav_path.exists():\n",
    "        wav_items = list(wav_path.iterdir())\n",
    "        print(f\"   Contiene {len(wav_items)} elementi:\")\n",
    "        for item in wav_items[:5]:\n",
    "            print(f\"      - {item.name} {'(DIR)' if item.is_dir() else ''}\")\n",
    "    print()\n",
    "    \n",
    "    # Controlla label folder\n",
    "    label_path = session1 / \"dialog\" / \"EmoEvaluation\"\n",
    "    print(f\"7Ô∏è‚É£  Percorso label: {label_path}\")\n",
    "    print(f\"   Esiste: {label_path.exists()}\")\n",
    "    if label_path.exists():\n",
    "        label_items = list(label_path.glob(\"*.txt\"))\n",
    "        print(f\"   Trovati {len(label_items)} file .txt\")\n",
    "        for item in label_items[:3]:\n",
    "            print(f\"      - {item.name}\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.custom_iemocap_dataset import CustomIEMOCAPDataset\n",
    "from utils.get_dataset_statistics import print_iemocap_stats\n",
    "print(\"=\"*80)\n",
    "print(\"üîÑ CREAZIONE DATASET E DATALOADER - IEMOCAP\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Verifica percorso\n",
    "if not iemocap_path or not Path(iemocap_path).exists():\n",
    "    raise ValueError(f\"‚ùå Dataset IEMOCAP non trovato in: {iemocap_path}\")\n",
    "\n",
    "print(f\"‚úÖ Usando dataset da: {iemocap_path}\\n\")\n",
    "\n",
    "# Crea i dataset\n",
    "train_iemocap_dataset = CustomIEMOCAPDataset(dataset_root=iemocap_path, split='train')\n",
    "val_iemocap_dataset = CustomIEMOCAPDataset(dataset_root=iemocap_path, split='validation')\n",
    "test_iemocap_dataset = CustomIEMOCAPDataset(dataset_root=iemocap_path, split='test')\n",
    "\n",
    "# Crea i dataloader\n",
    "batch_size = 32\n",
    "train_iemocap_dataloader = DataLoader(train_iemocap_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_iemocap_dataloader = DataLoader(val_iemocap_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_iemocap_dataloader = DataLoader(test_iemocap_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "# Riepilogo dataloader\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üì¶ DATALOADER SUMMARY - IEMOCAP\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Train Dataloader:      {len(train_iemocap_dataloader)} batch √ó {batch_size} samples = {len(train_iemocap_dataset)} totali\")\n",
    "print(f\"Validation Dataloader: {len(val_iemocap_dataloader)} batch √ó {batch_size} samples = {len(val_iemocap_dataset)} totali\")\n",
    "print(f\"Test Dataloader:       {len(test_iemocap_dataloader)} batch √ó {batch_size} samples = {len(test_iemocap_dataset)} totali\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Weights & Biases : Genera i grafici e compara gli esperimenti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4-dxDQOFcdgX"
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "import os\n",
    "os.environ['WANDB_API_KEY'] = '7ade30086de7899bed412e3eb5c2da065c146f90'\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "8q9OvEDHxmRv"
   },
   "outputs": [],
   "source": [
    "!python train.py --model CRNN_BiLSTM\n",
    "\n",
    "#!python train.py --model CRNN_BiGRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DyQo3klIymlz"
   },
   "source": [
    "# Step 5: Evaluate your model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9goKvp4jxk4j"
   },
   "outputs": [],
   "source": [
    "!python eval.py --model CRNN_BiLSTM --checkpoint checkpoints/best_model.pth\n",
    "\n",
    "#!python eval.py --model CRNN_BiGRU --checkpoint checkpoints/best_model.pth"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
