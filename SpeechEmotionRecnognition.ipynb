{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-E9qeg-6y1Hu"
   },
   "source": [
    "# LAB 3: How to setup a project from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XHmVt4s034WK"
   },
   "outputs": [],
   "source": [
    "!rm -rf speech-emotion-recognition-25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y6kJGhxzyN6d"
   },
   "source": [
    "# Step 1: Clone your project from Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Wfm084txMr0",
    "outputId": "91f0ad75-ff73-4cfb-b5f1-be42a8c96886"
   },
   "outputs": [],
   "source": [
    "#main\n",
    "#!git clone https://github.com/MatteoPaglia/speech-emotion-recognition-25.git\n",
    "\n",
    "#             nome branch\n",
    "\n",
    "!git clone -b TrainIEMOCAP https://github.com/MatteoPaglia/speech-emotion-recognition-25.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MN0lMneJxVz0",
    "outputId": "64b85f65-94db-4b58-9b9b-1e41effc2001"
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Pa5nOPxxbDf",
    "outputId": "cb19573e-9b7e-42c0-abe3-92b4fc6493de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/speech-emotion-recognition-25\n"
     ]
    }
   ],
   "source": [
    "# %cd mldl_project_skeleton\n",
    "%cd speech-emotion-recognition-25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VYilllpZzKMz",
    "outputId": "21364bda-49b5-450d-b782-846928e1bdd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " checkpoints\t\t    README.md\n",
      " config.py\t\t    requirements.txt\n",
      " data\t\t\t    SpeechEmotionRecnognition.ipynb\n",
      " dataset\t\t   'train IEMOCAP_on_CRNN.py'\n",
      "'eval IEMOCAP_on_CRNN.py'   train_IEMOCAP_on_CRNN.py\n",
      " eval_IEMOCAP_on_CRNN.py    train.py\n",
      " eval.py\t\t    utils\n",
      " models\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "be_4yDyp1Hru"
   },
   "source": [
    "# Step 2: Packages Installation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "EO9DuAYk1LFR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (1.7.4.5)\n",
      "Requirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (0.3.13)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (1.6.1)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (2.9.0+cpu)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (2.9.0+cpu)\n",
      "Requirement already satisfied: torchcodec in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (0.9.1)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (0.24.0+cpu)\n",
      "Requirement already satisfied: librosa in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (0.11.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (2.0.2)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 10)) (3.10.0)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 11)) (0.13.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 12)) (4.67.1)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 13)) (11.3.0)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 14)) (6.0.3)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle->-r requirements.txt (line 1)) (6.3.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle->-r requirements.txt (line 1)) (2025.11.12)\n",
      "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle->-r requirements.txt (line 1)) (3.4.4)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle->-r requirements.txt (line 1)) (3.11)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle->-r requirements.txt (line 1)) (5.29.5)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle->-r requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle->-r requirements.txt (line 1)) (8.0.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle->-r requirements.txt (line 1)) (2.32.4)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle->-r requirements.txt (line 1)) (75.2.0)\n",
      "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle->-r requirements.txt (line 1)) (1.17.0)\n",
      "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle->-r requirements.txt (line 1)) (1.3)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle->-r requirements.txt (line 1)) (2.5.0)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle->-r requirements.txt (line 1)) (0.5.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub->-r requirements.txt (line 2)) (25.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements.txt (line 3)) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements.txt (line 3)) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements.txt (line 3)) (3.6.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (2025.3.0)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.12/dist-packages (from librosa->-r requirements.txt (line 8)) (3.1.0)\n",
      "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.12/dist-packages (from librosa->-r requirements.txt (line 8)) (0.60.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from librosa->-r requirements.txt (line 8)) (4.4.2)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.12/dist-packages (from librosa->-r requirements.txt (line 8)) (0.13.1)\n",
      "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.12/dist-packages (from librosa->-r requirements.txt (line 8)) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from librosa->-r requirements.txt (line 8)) (1.0.0)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.12/dist-packages (from librosa->-r requirements.txt (line 8)) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa->-r requirements.txt (line 8)) (1.1.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 10)) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 10)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 10)) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 10)) (1.4.9)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 10)) (3.2.5)\n",
      "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.12/dist-packages (from seaborn->-r requirements.txt (line 11)) (2.2.2)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.51.0->librosa->-r requirements.txt (line 8)) (0.43.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->seaborn->-r requirements.txt (line 11)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->seaborn->-r requirements.txt (line 11)) (2025.3)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa->-r requirements.txt (line 8)) (4.5.1)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile>=0.12.1->librosa->-r requirements.txt (line 8)) (2.0.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->-r requirements.txt (line 4)) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->-r requirements.txt (line 4)) (3.0.3)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa->-r requirements.txt (line 8)) (2.23)\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bifSi62Ixrqr"
   },
   "source": [
    "# Step 3: Dataset Setup\n",
    "## Different options\n",
    "- First one is downloading using a script that places the data in the download folder (usually recommended)\n",
    "- Second one is uploading the dataset to your personal/institutional Google Drive and load it from there ([Read More](https://saturncloud.io/blog/google-colab-how-to-read-data-from-my-google-drive/))\n",
    "- Place the download script directly here on colab\n",
    "\n",
    "You are free to do as you please in this phase.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "DiWQTaTbxeIc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Configurazione Kaggle ---\n",
      "Kaggle configurato con successo.\n",
      "\n",
      "--- Download RAVDESS ---\n",
      "Contatto KaggleHub per scaricare: uwrfkaggler/ravdess-emotional-speech-audio...\n",
      "Using Colab cache for faster access to the 'ravdess-emotional-speech-audio' dataset.\n",
      "‚úì Dataset scaricato nella cache di sistema: /kaggle/input/ravdess-emotional-speech-audio\n",
      "RAVDESS pronto in cache: /kaggle/input/ravdess-emotional-speech-audio\n",
      "Numero totale di file: 2880\n",
      "\n",
      "--- Download IEMOCAP ---\n",
      "Contatto KaggleHub per scaricare: dejolilandry/iemocapfullrelease...\n",
      "Using Colab cache for faster access to the 'iemocapfullrelease' dataset.\n",
      "‚úì Dataset scaricato nella cache di sistema: /kaggle/input/iemocapfullrelease\n",
      "IEMOCAP pronto in cache: /kaggle/input/iemocapfullrelease\n",
      "Numero totale di file: 81249\n",
      "\n",
      "============================================================\n",
      "RIEPILOGO DOWNLOAD\n",
      "============================================================\n",
      "RAVDESS: ‚úÖ Successo\n",
      "IEMOCAP: ‚úÖ Successo\n",
      "============================================================\n",
      "\n",
      "üéâ Tutti i dataset sono stati scaricati con successo!\n"
     ]
    }
   ],
   "source": [
    "!python utils/download_dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üîç RICERCA PERCORSI DATASET\n",
      "================================================================================\n",
      "\n",
      "üìÅ Directory corrente: /content/speech-emotion-recognition-25\n",
      "\n",
      "üîé Ricerca IEMOCAP_full_release...\n",
      "‚úÖ IEMOCAP trovato a: /root/.cache/kagglehub/datasets/dejolilandry/iemocapfullrelease/versions/1/IEMOCAP_full_release\n",
      "\n",
      "üîé Ricerca ravdess-emotional-speech-audio...\n",
      "‚úÖ RAVDESS trovato a: /root/.cache/kagglehub/datasets/uwrfkaggler/ravdess-emotional-speech-audio\n",
      "\n",
      "üìÇ Contenuto della cartella 'data/' (se presente):\n",
      "   - .gitkeep\n",
      "\n",
      "================================================================================\n",
      "‚úÖ VARIABILI SALVATE:\n",
      "   - iemocap_path = /root/.cache/kagglehub/datasets/dejolilandry/iemocapfullrelease/versions/1/IEMOCAP_full_release\n",
      "   - ravdess_path = /root/.cache/kagglehub/datasets/uwrfkaggler/ravdess-emotional-speech-audio\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üîç RICERCA PERCORSI DATASET\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Percorsi possibili dove potrebbero essere i dataset\n",
    "possible_paths = [\n",
    "    Path('/kaggle/input/ravdess-emotional-speech-audio'),\n",
    "    Path.home() / '.cache' / 'kagglehub' / 'datasets',\n",
    "    Path('/root/.cache/kagglehub/datasets'),\n",
    "    Path('/tmp/kagglehub/datasets'),\n",
    "    Path('./data'),\n",
    "    Path('../data'),\n",
    "    Path('../../data'),\n",
    "]\n",
    "\n",
    "# Aggiungi anche la directory corrente\n",
    "possible_paths.append(Path.cwd())\n",
    "\n",
    "print(f\"\\nüìÅ Directory corrente: {Path.cwd()}\\n\")\n",
    "\n",
    "# Ricerca IEMOCAP\n",
    "print(\"üîé Ricerca IEMOCAP_full_release...\")\n",
    "iemocap_path = None\n",
    "iemocap_found = False\n",
    "for base_path in possible_paths:\n",
    "    if base_path.exists():\n",
    "        for root, dirs, files in os.walk(base_path):\n",
    "            if 'IEMOCAP_full_release' in dirs:\n",
    "                iemocap_path = Path(root) / 'IEMOCAP_full_release'\n",
    "                print(f\"‚úÖ IEMOCAP trovato a: {iemocap_path}\")\n",
    "                iemocap_found = True\n",
    "                break\n",
    "    if iemocap_found:\n",
    "        break\n",
    "\n",
    "if not iemocap_found:\n",
    "    print(\"‚ùå IEMOCAP non trovato nei percorsi standard\")\n",
    "    iemocap_path = None\n",
    "\n",
    "# Ricerca RAVDESS\n",
    "print(\"\\nüîé Ricerca ravdess-emotional-speech-audio...\")\n",
    "ravdess_path = None\n",
    "ravdess_found = False\n",
    "for base_path in possible_paths:\n",
    "    if base_path.exists():\n",
    "        for root, dirs, files in os.walk(base_path):\n",
    "            if 'ravdess-emotional-speech-audio' in dirs:\n",
    "                ravdess_path = Path(root) / 'ravdess-emotional-speech-audio'\n",
    "                print(f\"‚úÖ RAVDESS trovato a: {ravdess_path}\")\n",
    "                ravdess_found = True\n",
    "                break\n",
    "    if ravdess_found:\n",
    "        break\n",
    "\n",
    "if not ravdess_found:\n",
    "    print(\"‚ùå RAVDESS non trovato nei percorsi standard\")\n",
    "    ravdess_path = None\n",
    "\n",
    "# Lista contenuti della directory data/ se esiste\n",
    "print(\"\\nüìÇ Contenuto della cartella 'data/' (se presente):\")\n",
    "data_dir = Path('./data')\n",
    "if data_dir.exists():\n",
    "    for item in data_dir.iterdir():\n",
    "        print(f\"   - {item.name}\")\n",
    "else:\n",
    "    print(\"   ‚ùå Cartella 'data/' non trovata\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ VARIABILI SALVATE:\")\n",
    "print(f\"   - iemocap_path = {iemocap_path}\")\n",
    "print(f\"   - ravdess_path = {ravdess_path}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "////////////////////////////////////////////////////////////////////////////////////////////\n",
      "Dataset IEMOCAP\n",
      "////////////////////////////////////////////////////////////////////////////////////////////\n",
      "‚úÖ Usando percorso trovato: /root/.cache/kagglehub/datasets/dejolilandry/iemocapfullrelease/versions/1/IEMOCAP_full_release\n",
      "‚úÖ Caricate 5531 etichette\n",
      "üîç Raccogliendo campioni audio...\n",
      "‚úÖ Raccolti 2943 campioni audio\n",
      "   - Solo campioni improvvisati\n",
      "   - Emozioni: ['neutral', 'happy', 'sad', 'angry', 'happy']\n",
      "üìä Statistiche del dataset IEMOCAP:\n",
      "\n",
      "============================================================\n",
      "üìä ANALISI IEMOCAP TRAINING SET\n",
      "============================================================\n",
      "\n",
      "üîπ SAMPLES TOTALI: 1678\n",
      "üîπ SESSIONI: ['1', '2', '3']\n",
      "üîπ SPEAKER UNICI (session, gender): 6\n",
      "   Elenco: [('1', 'F'), ('1', 'M'), ('2', 'F'), ('2', 'M'), ('3', 'F'), ('3', 'M')]\n",
      "üîπ IMPROVVISAZIONI UNICHE: 8\n",
      "\n",
      "üë• SPEAKER INDEPENDENCE (per verificare leakage):\n",
      "   - Sessione 1: (Ses1, F), (Ses1, M)\n",
      "   - Sessione 2: (Ses2, F), (Ses2, M)\n",
      "   - Sessione 3: (Ses3, F), (Ses3, M)\n",
      "\n",
      "üé≠ DISTRIBUZIONE EMOZIONI:\n",
      "   - Angry     :  174 ( 10.4%) ‚ñà‚ñà\n",
      "   - Happy     :  472 ( 28.1%) ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   - Neutral   :  638 ( 38.0%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   - Sad       :  394 ( 23.5%) ‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "üìã DISTRIBUZIONE CAMPIONI PER SESSIONE:\n",
      "   - Sessione 1:  521 ( 31.0%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      ‚îî‚îÄ Angry     :  62 ( 11.9%)\n",
      "      ‚îî‚îÄ Happy     : 132 ( 25.3%)\n",
      "      ‚îî‚îÄ Neutral   : 223 ( 42.8%)\n",
      "      ‚îî‚îÄ Sad       : 104 ( 20.0%)\n",
      "   - Sessione 2:  530 ( 31.6%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      ‚îî‚îÄ Angry     :  22 (  4.2%)\n",
      "      ‚îî‚îÄ Happy     : 191 ( 36.0%)\n",
      "      ‚îî‚îÄ Neutral   : 217 ( 40.9%)\n",
      "      ‚îî‚îÄ Sad       : 100 ( 18.9%)\n",
      "   - Sessione 3:  627 ( 37.4%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      ‚îî‚îÄ Angry     :  90 ( 14.4%)\n",
      "      ‚îî‚îÄ Happy     : 149 ( 23.8%)\n",
      "      ‚îî‚îÄ Neutral   : 198 ( 31.6%)\n",
      "      ‚îî‚îÄ Sad       : 190 ( 30.3%)\n",
      "------------------------------------------------------------\n",
      "‚úÖ Dataset initialized: 1678 train samples\n",
      "‚úÖ Caricate 5531 etichette\n",
      "üîç Raccogliendo campioni audio...\n",
      "‚úÖ Raccolti 2943 campioni audio\n",
      "   - Solo campioni improvvisati\n",
      "   - Emozioni: ['neutral', 'happy', 'sad', 'angry', 'happy']\n",
      "üìä Statistiche del dataset IEMOCAP:\n",
      "\n",
      "============================================================\n",
      "üìä ANALISI IEMOCAP VALIDATION SET\n",
      "============================================================\n",
      "\n",
      "üîπ SAMPLES TOTALI: 534\n",
      "üîπ SESSIONI: ['4']\n",
      "üîπ SPEAKER UNICI (session, gender): 2\n",
      "   Elenco: [('4', 'F'), ('4', 'M')]\n",
      "üîπ IMPROVVISAZIONI UNICHE: 8\n",
      "\n",
      "üë• SPEAKER INDEPENDENCE (per verificare leakage):\n",
      "   - Sessione 4: (Ses4, F), (Ses4, M)\n",
      "\n",
      "üé≠ DISTRIBUZIONE EMOZIONI:\n",
      "   - Angry     :   84 ( 15.7%) ‚ñà‚ñà‚ñà\n",
      "   - Happy     :  195 ( 36.5%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   - Neutral   :  174 ( 32.6%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   - Sad       :   81 ( 15.2%) ‚ñà‚ñà‚ñà\n",
      "\n",
      "üìã DISTRIBUZIONE CAMPIONI PER SESSIONE:\n",
      "   - Sessione 4:  534 (100.0%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      ‚îî‚îÄ Angry     :  84 ( 15.7%)\n",
      "      ‚îî‚îÄ Happy     : 195 ( 36.5%)\n",
      "      ‚îî‚îÄ Neutral   : 174 ( 32.6%)\n",
      "      ‚îî‚îÄ Sad       :  81 ( 15.2%)\n",
      "------------------------------------------------------------\n",
      "‚úÖ Dataset initialized: 534 validation samples\n",
      "‚úÖ Caricate 5531 etichette\n",
      "üîç Raccogliendo campioni audio...\n",
      "‚úÖ Raccolti 2943 campioni audio\n",
      "   - Solo campioni improvvisati\n",
      "   - Emozioni: ['neutral', 'happy', 'sad', 'angry', 'happy']\n",
      "üìä Statistiche del dataset IEMOCAP:\n",
      "\n",
      "============================================================\n",
      "üìä ANALISI IEMOCAP TEST SET\n",
      "============================================================\n",
      "\n",
      "üîπ SAMPLES TOTALI: 731\n",
      "üîπ SESSIONI: ['5']\n",
      "üîπ SPEAKER UNICI (session, gender): 2\n",
      "   Elenco: [('5', 'F'), ('5', 'M')]\n",
      "üîπ IMPROVVISAZIONI UNICHE: 8\n",
      "\n",
      "üë• SPEAKER INDEPENDENCE (per verificare leakage):\n",
      "   - Sessione 5: (Ses5, F), (Ses5, M)\n",
      "\n",
      "üé≠ DISTRIBUZIONE EMOZIONI:\n",
      "   - Angry     :   31 (  4.2%) \n",
      "   - Happy     :  280 ( 38.3%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   - Neutral   :  287 ( 39.3%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   - Sad       :  133 ( 18.2%) ‚ñà‚ñà‚ñà\n",
      "\n",
      "üìã DISTRIBUZIONE CAMPIONI PER SESSIONE:\n",
      "   - Sessione 5:  731 (100.0%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      ‚îî‚îÄ Angry     :  31 (  4.2%)\n",
      "      ‚îî‚îÄ Happy     : 280 ( 38.3%)\n",
      "      ‚îî‚îÄ Neutral   : 287 ( 39.3%)\n",
      "      ‚îî‚îÄ Sad       : 133 ( 18.2%)\n",
      "------------------------------------------------------------\n",
      "‚úÖ Dataset initialized: 731 test samples\n",
      "Train samples: 1678\n",
      "Val samples: 534\n",
      "Test samples: 731\n",
      "////////////////////////////////////////////////////////////////////////////////////////////\n",
      "Dataset RAVDESS\n",
      "////////////////////////////////////////////////////////////////////////////////////////////\n",
      "‚úÖ Usando percorso trovato: /root/.cache/kagglehub/datasets/uwrfkaggler/ravdess-emotional-speech-audio\n",
      "üìä Statistiche del dataset RAVDESS:\n",
      "\n",
      "========================================\n",
      "üìä ANALISI RAVDESS TRAINING SET\n",
      "========================================\n",
      "üîπ Samples Totali: 1440\n",
      "üîπ Attori (20): [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
      "   - Maschi:  10\n",
      "   - Femmine: 10\n",
      "\n",
      "üé≠ Distribuzione Emozioni:\n",
      "   - Angry     :  320 ( 22.2%) ‚ñà‚ñà‚ñà‚ñà\n",
      "   - Happy     :  320 ( 22.2%) ‚ñà‚ñà‚ñà‚ñà\n",
      "   - Neutral   :  480 ( 33.3%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   - Sad       :  320 ( 22.2%) ‚ñà‚ñà‚ñà‚ñà\n",
      "----------------------------------------\n",
      "üìä Statistiche del dataset RAVDESS:\n",
      "\n",
      "========================================\n",
      "üìä ANALISI RAVDESS VALIDATION SET\n",
      "========================================\n",
      "üîπ Samples Totali: 144\n",
      "üîπ Attori (2): [21, 22]\n",
      "   - Maschi:  1\n",
      "   - Femmine: 1\n",
      "\n",
      "üé≠ Distribuzione Emozioni:\n",
      "   - Angry     :   32 ( 22.2%) ‚ñà‚ñà‚ñà‚ñà\n",
      "   - Happy     :   32 ( 22.2%) ‚ñà‚ñà‚ñà‚ñà\n",
      "   - Neutral   :   48 ( 33.3%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   - Sad       :   32 ( 22.2%) ‚ñà‚ñà‚ñà‚ñà\n",
      "----------------------------------------\n",
      "üìä Statistiche del dataset RAVDESS:\n",
      "\n",
      "========================================\n",
      "üìä ANALISI RAVDESS TEST SET\n",
      "========================================\n",
      "üîπ Samples Totali: 144\n",
      "üîπ Attori (2): [23, 24]\n",
      "   - Maschi:  1\n",
      "   - Femmine: 1\n",
      "\n",
      "üé≠ Distribuzione Emozioni:\n",
      "   - Angry     :   32 ( 22.2%) ‚ñà‚ñà‚ñà‚ñà\n",
      "   - Happy     :   32 ( 22.2%) ‚ñà‚ñà‚ñà‚ñà\n",
      "   - Neutral   :   48 ( 33.3%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   - Sad       :   32 ( 22.2%) ‚ñà‚ñà‚ñà‚ñà\n",
      "----------------------------------------\n",
      "Train samples: 1440\n",
      "Val samples: 144\n",
      "Test samples: 144\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from dataset.custom_iemocap_dataset import CustomIEMOCAPDataset\n",
    "from dataset.custom_ravdess_dataset import CustomRAVDESSDataset\n",
    "\n",
    "print(f\"////////////////////////////////////////////////////////////////////////////////////////////\")\n",
    "print(f\"Dataset IEMOCAP\")\n",
    "print(f\"////////////////////////////////////////////////////////////////////////////////////////////\")\n",
    "\n",
    "# Usa il percorso trovato in precedenza, altrimenti fallback\n",
    "if iemocap_path and iemocap_path.exists():\n",
    "    dataset_IEMOCAP_path = str(iemocap_path)\n",
    "    print(f\"‚úÖ Usando percorso trovato: {dataset_IEMOCAP_path}\")\n",
    "else:\n",
    "    dataset_IEMOCAP_path = '/kaggle/input/iemocapfullrelease/IEMOCAP_full_release'\n",
    "    print(f\"‚ö†Ô∏è  Percorso non trovato, usando fallback: {dataset_IEMOCAP_path}\")\n",
    "\n",
    "# Create IEMOCAPdatasets\n",
    "train_IEMOCAP_dataset = CustomIEMOCAPDataset(dataset_root=dataset_IEMOCAP_path, split='train')\n",
    "val_IEMOCAP_dataset = CustomIEMOCAPDataset(dataset_root=dataset_IEMOCAP_path, split='validation')\n",
    "test_IEMOCAP_dataset = CustomIEMOCAPDataset(dataset_root=dataset_IEMOCAP_path, split='test')\n",
    "\n",
    "print(f\"Train samples: {len(train_IEMOCAP_dataset)}\")\n",
    "print(f\"Val samples: {len(val_IEMOCAP_dataset)}\")\n",
    "print(f\"Test samples: {len(test_IEMOCAP_dataset)}\")\n",
    "\n",
    "# Create IEMOCAP DataLoaders\n",
    "batch_size = 4\n",
    "train_IEMOCAP_dataloader = DataLoader(train_IEMOCAP_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_IEMOCAP_dataloader = DataLoader(val_IEMOCAP_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_IEMOCAP_dataloader = DataLoader(test_IEMOCAP_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "print(f\"////////////////////////////////////////////////////////////////////////////////////////////\")\n",
    "print(f\"Dataset RAVDESS\")\n",
    "print(f\"////////////////////////////////////////////////////////////////////////////////////////////\")\n",
    "\n",
    "# Usa il percorso trovato in precedenza, altrimenti fallback\n",
    "if ravdess_path and ravdess_path.exists():\n",
    "    dataset_RAVDESS_path = str(ravdess_path)\n",
    "    print(f\"‚úÖ Usando percorso trovato: {dataset_RAVDESS_path}\")\n",
    "else:\n",
    "    dataset_RAVDESS_path = '/kaggle/input/ravdess-emotional-speech-audio'\n",
    "    print(f\"‚ö†Ô∏è  Percorso non trovato, usando fallback: {dataset_RAVDESS_path}\")\n",
    "\n",
    "# Create RAVDESS datasets\n",
    "train_RAVDESS_dataset = CustomRAVDESSDataset(dataset_root=dataset_RAVDESS_path, split='train')\n",
    "val_RAVDESS_dataset = CustomRAVDESSDataset(dataset_root=dataset_RAVDESS_path, split='validation')\n",
    "test_RAVDESS_dataset = CustomRAVDESSDataset(dataset_root=dataset_RAVDESS_path, split='test')\n",
    "\n",
    "print(f\"Train samples: {len(train_RAVDESS_dataset)}\")\n",
    "print(f\"Val samples: {len(val_RAVDESS_dataset)}\")\n",
    "print(f\"Test samples: {len(test_RAVDESS_dataset)}\")\n",
    "\n",
    "# Create RAVDESS DataLoaders\n",
    "batch_size = 4\n",
    "train_RAVDESS_dataloader = DataLoader(train_RAVDESS_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_RAVDESS_dataloader = DataLoader(val_RAVDESS_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_RAVDESS_dataloader = DataLoader(test_RAVDESS_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sqo9Eh79yihI"
   },
   "source": [
    "# Step 4: Train your model and visualize training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "4-dxDQOFcdgX"
   },
   "outputs": [],
   "source": [
    "#%env WANDB_API_KEY=\"7ade30086de7899bed412e3eb5c2da065c146f90\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "id": "8q9OvEDHxmRv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Classe SimpleEarlyStopping pronta!\n",
      "Using device: cpu\n",
      "Dataset: IEMOCAP\n",
      "\n",
      "‚úÖ IEMOCAP trovato: /root/.cache/kagglehub/datasets/dejolilandry/iemocapfullrelease/versions/1/IEMOCAP_full_release\n",
      "\n",
      "üìä Caricamento IEMOCAP dataset...\n",
      "‚úÖ Caricate 5531 etichette\n",
      "üîç Raccogliendo campioni audio...\n",
      "‚úÖ Raccolti 2943 campioni audio\n",
      "   - Solo campioni improvvisati\n",
      "   - Emozioni: ['neutral', 'happy', 'sad', 'angry', 'happy']\n",
      "üìä Statistiche del dataset IEMOCAP:\n",
      "\n",
      "============================================================\n",
      "üìä ANALISI IEMOCAP TRAINING SET\n",
      "============================================================\n",
      "\n",
      "üîπ SAMPLES TOTALI: 1678\n",
      "üîπ SESSIONI: ['1', '2', '3']\n",
      "üîπ SPEAKER UNICI (session, gender): 6\n",
      "   Elenco: [('1', 'F'), ('1', 'M'), ('2', 'F'), ('2', 'M'), ('3', 'F'), ('3', 'M')]\n",
      "üîπ IMPROVVISAZIONI UNICHE: 8\n",
      "\n",
      "üë• SPEAKER INDEPENDENCE (per verificare leakage):\n",
      "   - Sessione 1: (Ses1, F), (Ses1, M)\n",
      "   - Sessione 2: (Ses2, F), (Ses2, M)\n",
      "   - Sessione 3: (Ses3, F), (Ses3, M)\n",
      "\n",
      "üé≠ DISTRIBUZIONE EMOZIONI:\n",
      "   - Angry     :  174 ( 10.4%) ‚ñà‚ñà\n",
      "   - Happy     :  472 ( 28.1%) ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   - Neutral   :  638 ( 38.0%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   - Sad       :  394 ( 23.5%) ‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "üìã DISTRIBUZIONE CAMPIONI PER SESSIONE:\n",
      "   - Sessione 1:  521 ( 31.0%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      ‚îî‚îÄ Angry     :  62 ( 11.9%)\n",
      "      ‚îî‚îÄ Happy     : 132 ( 25.3%)\n",
      "      ‚îî‚îÄ Neutral   : 223 ( 42.8%)\n",
      "      ‚îî‚îÄ Sad       : 104 ( 20.0%)\n",
      "   - Sessione 2:  530 ( 31.6%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      ‚îî‚îÄ Angry     :  22 (  4.2%)\n",
      "      ‚îî‚îÄ Happy     : 191 ( 36.0%)\n",
      "      ‚îî‚îÄ Neutral   : 217 ( 40.9%)\n",
      "      ‚îî‚îÄ Sad       : 100 ( 18.9%)\n",
      "   - Sessione 3:  627 ( 37.4%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      ‚îî‚îÄ Angry     :  90 ( 14.4%)\n",
      "      ‚îî‚îÄ Happy     : 149 ( 23.8%)\n",
      "      ‚îî‚îÄ Neutral   : 198 ( 31.6%)\n",
      "      ‚îî‚îÄ Sad       : 190 ( 30.3%)\n",
      "------------------------------------------------------------\n",
      "‚úÖ Dataset initialized: 1678 train samples\n",
      "‚úÖ Caricate 5531 etichette\n",
      "üîç Raccogliendo campioni audio...\n",
      "‚úÖ Raccolti 2943 campioni audio\n",
      "   - Solo campioni improvvisati\n",
      "   - Emozioni: ['neutral', 'happy', 'sad', 'angry', 'happy']\n",
      "üìä Statistiche del dataset IEMOCAP:\n",
      "\n",
      "============================================================\n",
      "üìä ANALISI IEMOCAP VALIDATION SET\n",
      "============================================================\n",
      "\n",
      "üîπ SAMPLES TOTALI: 534\n",
      "üîπ SESSIONI: ['4']\n",
      "üîπ SPEAKER UNICI (session, gender): 2\n",
      "   Elenco: [('4', 'F'), ('4', 'M')]\n",
      "üîπ IMPROVVISAZIONI UNICHE: 8\n",
      "\n",
      "üë• SPEAKER INDEPENDENCE (per verificare leakage):\n",
      "   - Sessione 4: (Ses4, F), (Ses4, M)\n",
      "\n",
      "üé≠ DISTRIBUZIONE EMOZIONI:\n",
      "   - Angry     :   84 ( 15.7%) ‚ñà‚ñà‚ñà\n",
      "   - Happy     :  195 ( 36.5%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   - Neutral   :  174 ( 32.6%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   - Sad       :   81 ( 15.2%) ‚ñà‚ñà‚ñà\n",
      "\n",
      "üìã DISTRIBUZIONE CAMPIONI PER SESSIONE:\n",
      "   - Sessione 4:  534 (100.0%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      ‚îî‚îÄ Angry     :  84 ( 15.7%)\n",
      "      ‚îî‚îÄ Happy     : 195 ( 36.5%)\n",
      "      ‚îî‚îÄ Neutral   : 174 ( 32.6%)\n",
      "      ‚îî‚îÄ Sad       :  81 ( 15.2%)\n",
      "------------------------------------------------------------\n",
      "‚úÖ Dataset initialized: 534 validation samples\n",
      "Train samples: 1678\n",
      "Val samples: 534\n",
      "\n",
      "================================================================================\n",
      "üèóÔ∏è ARCHITETTURA DEL MODELLO\n",
      "================================================================================\n",
      "CRNN_BiLSTM(\n",
      "  (block1): Sequential(\n",
      "    (0): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (block2): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (block3): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (block4): Sequential(\n",
      "    (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (projection): Linear(in_features=1024, out_features=128, bias=True)\n",
      "  (lstm): LSTM(128, 128, batch_first=True, bidirectional=True)\n",
      "  (attention_linear): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (classifier): Linear(in_features=256, out_features=4, bias=True)\n",
      ")\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üîß IPERPARAMETRI DI TRAINING\n",
      "================================================================================\n",
      "Device:                cpu\n",
      "Dataset:               IEMOCAP\n",
      "Batch Size:            32\n",
      "Learning Rate:         0.0001\n",
      "Weight Decay (L2):     0.001\n",
      "Number of Epochs:      100\n",
      "Early Stopping Patience: 10\n",
      "\n",
      "Modello:\n",
      "  - Num Classes:       4\n",
      "  - Time Steps:        200\n",
      "  - Mel Bands:         128\n",
      "\n",
      "Optimizer:             Adam\n",
      "Loss Function:         CrossEntropyLoss\n",
      "Train Samples:         1678\n",
      "Val Samples:           534\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Epoch 1/100\n",
      "Training:   0% 0/53 [00:00<?, ?it/s]\n",
      "üìä Calcolando statistiche durata POST-TRIMMING per split 'train'...\n",
      "   335/1678 file processati...\n",
      "   670/1678 file processati...\n",
      "   1005/1678 file processati...\n",
      "   1340/1678 file processati...\n",
      "   1675/1678 file processati...\n",
      "‚úÖ Media: 4.29s (68692 campioni)\n",
      "‚úÖ Massimo: 29.13s (466079 campioni)\n",
      "\n",
      "Traceback (most recent call last):  \n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/collate.py\", line 172, in collate\n",
      "    key: collate(\n",
      "         ^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/collate.py\", line 240, in collate\n",
      "    raise TypeError(default_collate_err_msg_format.format(elem_type))\n",
      "TypeError: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'NoneType'>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/content/speech-emotion-recognition-25/train_IEMOCAP_on_CRNN.py\", line 201, in <module>\n",
      "    train_loss, train_acc = train_one_epoch(model, train_dataloader, criterion, optimizer, DEVICE)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/content/speech-emotion-recognition-25/train_IEMOCAP_on_CRNN.py\", line 79, in train_one_epoch\n",
      "    for batch in loop:\n",
      "                 ^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/tqdm/std.py\", line 1181, in __iter__\n",
      "    for obj in iterable:\n",
      "               ^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 732, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 788, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\", line 55, in fetch\n",
      "    return self.collate_fn(data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/collate.py\", line 398, in default_collate\n",
      "    return collate(batch, collate_fn_map=default_collate_fn_map)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/collate.py\", line 192, in collate\n",
      "    key: collate([d[key] for d in batch], collate_fn_map=collate_fn_map)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/collate.py\", line 240, in collate\n",
      "    raise TypeError(default_collate_err_msg_format.format(elem_type))\n",
      "TypeError: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'NoneType'>\n"
     ]
    }
   ],
   "source": [
    "#!python train.py\n",
    "!python train_IEMOCAP_on_CRNN.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DyQo3klIymlz"
   },
   "source": [
    "# Step 5: Evaluate your model\n",
    "\n",
    "1.   List item\n",
    "2.   List item\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "9goKvp4jxk4j"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Dataset: IEMOCAP\n",
      "\n",
      "‚úÖ IEMOCAP trovato: /root/.cache/kagglehub/datasets/dejolilandry/iemocapfullrelease/versions/1/IEMOCAP_full_release\n",
      "\n",
      "Loading IEMOCAP test set...\n",
      "‚úÖ Caricate 5531 etichette\n",
      "üîç Raccogliendo campioni audio...\n",
      "‚úÖ Raccolti 2943 campioni audio\n",
      "   - Solo campioni improvvisati\n",
      "   - Emozioni: ['neutral', 'happy', 'sad', 'angry', 'happy']\n",
      "üìä Statistiche del dataset IEMOCAP:\n",
      "\n",
      "============================================================\n",
      "üìä ANALISI IEMOCAP TEST SET\n",
      "============================================================\n",
      "\n",
      "üîπ SAMPLES TOTALI: 731\n",
      "üîπ SESSIONI: ['5']\n",
      "üîπ SPEAKER UNICI (session, gender): 2\n",
      "   Elenco: [('5', 'F'), ('5', 'M')]\n",
      "üîπ IMPROVVISAZIONI UNICHE: 8\n",
      "\n",
      "üë• SPEAKER INDEPENDENCE (per verificare leakage):\n",
      "   - Sessione 5: (Ses5, F), (Ses5, M)\n",
      "\n",
      "üé≠ DISTRIBUZIONE EMOZIONI:\n",
      "   - Angry     :   31 (  4.2%) \n",
      "   - Happy     :  280 ( 38.3%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   - Neutral   :  287 ( 39.3%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   - Sad       :  133 ( 18.2%) ‚ñà‚ñà‚ñà\n",
      "\n",
      "üìã DISTRIBUZIONE CAMPIONI PER SESSIONE:\n",
      "   - Sessione 5:  731 (100.0%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      ‚îî‚îÄ Angry     :  31 (  4.2%)\n",
      "      ‚îî‚îÄ Happy     : 280 ( 38.3%)\n",
      "      ‚îî‚îÄ Neutral   : 287 ( 39.3%)\n",
      "      ‚îî‚îÄ Sad       : 133 ( 18.2%)\n",
      "------------------------------------------------------------\n",
      "‚úÖ Dataset initialized: 731 test samples\n",
      "‚úÖ Test samples: 731\n",
      "\n",
      "Loading model...\n",
      "Traceback (most recent call last):\n",
      "  File \"/content/speech-emotion-recognition-25/eval_IEMOCAP_on_CRNN.py\", line 140, in <module>\n",
      "    raise FileNotFoundError(f\"‚ùå Modello non trovato: {MODEL_PATH}\\n   Assicurati di aver eseguito il training prima!\")\n",
      "FileNotFoundError: ‚ùå Modello non trovato: checkpoints/best_model_iemocap.pth\n",
      "   Assicurati di aver eseguito il training prima!\n"
     ]
    }
   ],
   "source": [
    "#!python eval.py\n",
    "!python eval_IEMOCAP_on_CRNN.py"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
