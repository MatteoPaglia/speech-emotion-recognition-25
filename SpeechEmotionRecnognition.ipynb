{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-E9qeg-6y1Hu"
   },
   "source": [
    "# LAB 3: How to setup a project from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "XHmVt4s034WK"
   },
   "outputs": [],
   "source": [
    "!rm -rf speech-emotion-recognition-25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y6kJGhxzyN6d"
   },
   "source": [
    "# Step 1: Clone your project from Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Wfm084txMr0",
    "outputId": "91f0ad75-ff73-4cfb-b5f1-be42a8c96886"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'speech-emotion-recognition-25'...\n",
      "remote: Enumerating objects: 176, done.\u001b[K\n",
      "remote: Counting objects: 100% (82/82), done.\u001b[K\n",
      "remote: Compressing objects: 100% (55/55), done.\u001b[K\n",
      "remote: Total 176 (delta 57), reused 47 (delta 25), pack-reused 94 (from 3)\u001b[K\n",
      "Receiving objects: 100% (176/176), 62.25 KiB | 12.45 MiB/s, done.\n",
      "Resolving deltas: 100% (93/93), done.\n"
     ]
    }
   ],
   "source": [
    "#main\n",
    "#!git clone https://github.com/MatteoPaglia/speech-emotion-recognition-25.git\n",
    "\n",
    "#             nome branch\n",
    "\n",
    "!git clone -b IemocapClass https://github.com/MatteoPaglia/speech-emotion-recognition-25.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MN0lMneJxVz0",
    "outputId": "64b85f65-94db-4b58-9b9b-1e41effc2001"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_data  speech-emotion-recognition-25\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Pa5nOPxxbDf",
    "outputId": "cb19573e-9b7e-42c0-abe3-92b4fc6493de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/speech-emotion-recognition-25\n"
     ]
    }
   ],
   "source": [
    "# %cd mldl_project_skeleton\n",
    "%cd speech-emotion-recognition-25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VYilllpZzKMz",
    "outputId": "21364bda-49b5-450d-b782-846928e1bdd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints  dataset  models\t requirements.txt\t\t  train.py\n",
      "data\t     eval.py  README.md  SpeechEmotionRecnognition.ipynb  utils\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "be_4yDyp1Hru"
   },
   "source": [
    "# Step 2: Packages Installation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "EO9DuAYk1LFR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (1.7.4.5)\n",
      "Requirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (0.3.13)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (1.6.1)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle->-r requirements.txt (line 1)) (6.3.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle->-r requirements.txt (line 1)) (2025.11.12)\n",
      "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle->-r requirements.txt (line 1)) (3.4.4)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle->-r requirements.txt (line 1)) (3.11)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle->-r requirements.txt (line 1)) (5.29.5)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle->-r requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle->-r requirements.txt (line 1)) (8.0.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle->-r requirements.txt (line 1)) (2.32.4)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle->-r requirements.txt (line 1)) (75.2.0)\n",
      "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle->-r requirements.txt (line 1)) (1.17.0)\n",
      "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle->-r requirements.txt (line 1)) (1.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kaggle->-r requirements.txt (line 1)) (4.67.1)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle->-r requirements.txt (line 1)) (2.5.0)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle->-r requirements.txt (line 1)) (0.5.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub->-r requirements.txt (line 2)) (25.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub->-r requirements.txt (line 2)) (6.0.3)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements.txt (line 3)) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements.txt (line 3)) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements.txt (line 3)) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements.txt (line 3)) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bifSi62Ixrqr"
   },
   "source": [
    "# Step 3: Dataset Setup\n",
    "## Different options\n",
    "- First one is downloading using a script that places the data in the download folder (usually recommended)\n",
    "- Second one is uploading the dataset to your personal/institutional Google Drive and load it from there ([Read More](https://saturncloud.io/blog/google-colab-how-to-read-data-from-my-google-drive/))\n",
    "- Place the download script directly here on colab\n",
    "\n",
    "You are free to do as you please in this phase.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "DiWQTaTbxeIc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Configurazione Kaggle ---\n",
      "Kaggle configurato con successo.\n",
      "\n",
      "--- Download RAVDESS ---\n",
      "Contatto KaggleHub per scaricare: uwrfkaggler/ravdess-emotional-speech-audio...\n",
      "Using Colab cache for faster access to the 'ravdess-emotional-speech-audio' dataset.\n",
      "‚úì Dataset scaricato nella cache di sistema: /kaggle/input/ravdess-emotional-speech-audio\n",
      "RAVDESS pronto in cache: /kaggle/input/ravdess-emotional-speech-audio\n",
      "Numero totale di file: 2880\n",
      "\n",
      "--- Download IEMOCAP ---\n",
      "Contatto KaggleHub per scaricare: dejolilandry/iemocapfullrelease...\n",
      "Using Colab cache for faster access to the 'iemocapfullrelease' dataset.\n",
      "‚úì Dataset scaricato nella cache di sistema: /kaggle/input/iemocapfullrelease\n",
      "IEMOCAP pronto in cache: /kaggle/input/iemocapfullrelease\n",
      "Numero totale di file: 81249\n",
      "\n",
      "============================================================\n",
      "RIEPILOGO DOWNLOAD\n",
      "============================================================\n",
      "RAVDESS: ‚úÖ Successo\n",
      "IEMOCAP: ‚úÖ Successo\n",
      "============================================================\n",
      "\n",
      "üéâ Tutti i dataset sono stati scaricati con successo!\n"
     ]
    }
   ],
   "source": [
    "!python utils/download_dataset.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3.5: Improvised Vocal Recording\n",
    "\n",
    "Model IEMOCAP dataset to extract only improvised audio. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "KAGGLEHUB CACHE EXPLORATION\n",
      "================================================================================\n",
      "‚úì Base cache directory exists: /root/.cache/kagglehub/datasets/dejolilandry/iemocapfullrelease\n",
      "\n",
      "Contents of cache directory:\n",
      "  1.complete\n",
      "  versions/ \n",
      "\n",
      "‚úì Versions directory exists: /root/.cache/kagglehub/datasets/dejolilandry/iemocapfullrelease/versions\n",
      "Contents of versions/:\n",
      "  1/ \n",
      "    Contents of 1/:\n",
      "      IEMOCAP_full_release/ \n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Check kagglehub cache directory\n",
    "kaggle_cache_base = Path('/root/.cache/kagglehub/datasets/dejolilandry/iemocapfullrelease')\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"KAGGLEHUB CACHE EXPLORATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if kaggle_cache_base.exists():\n",
    "    print(f\"‚úì Base cache directory exists: {kaggle_cache_base}\\n\")\n",
    "    \n",
    "    # Check versions subdirectory\n",
    "    versions_dir = kaggle_cache_base / 'versions'\n",
    "    if versions_dir.exists():\n",
    "        print(f\"‚úì Versions directory exists\\n\")\n",
    "        \n",
    "        for version in sorted(versions_dir.iterdir()):\n",
    "            if version.is_dir():\n",
    "                print(f\"üìÇ Version: {version.name}/\")\n",
    "                \n",
    "                # Show IEMOCAP_full_release\n",
    "                iemocap_dir = version / 'IEMOCAP_full_release'\n",
    "                if iemocap_dir.exists():\n",
    "                    print(f\"  ‚îî‚îÄ üìÇ IEMOCAP_full_release/\")\n",
    "                    \n",
    "                    # Show Sessions\n",
    "                    sessions = sorted([d for d in iemocap_dir.iterdir() if d.is_dir() and d.name.startswith('Session')])\n",
    "                    print(f\"    ‚îî‚îÄ Found {len(sessions)} sessions:\")\n",
    "                    \n",
    "                    for session_dir in sessions[:2]:  # Show first 2 sessions\n",
    "                        print(f\"      üìÅ {session_dir.name}/\")\n",
    "                        \n",
    "                        # Show subdirectories in session\n",
    "                        subdirs = sorted([d.name for d in session_dir.iterdir() if d.is_dir()])\n",
    "                        for subdir_name in subdirs[:5]:  # Show first 5 subdirs\n",
    "                            print(f\"        ‚îú‚îÄ {subdir_name}/\")\n",
    "                        \n",
    "                        if len(subdirs) > 5:\n",
    "                            print(f\"        ‚îî‚îÄ ... and {len(subdirs) - 5} more\")\n",
    "                    \n",
    "                    if len(sessions) > 2:\n",
    "                        print(f\"      ... and {len(sessions) - 2} more sessions\")\n",
    "else:\n",
    "    print(f\"‚úó Cache directory not found: {kaggle_cache_base}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Found IEMOCAP in kagglehub cache\n",
      "üìÇ Using dataset path: /root/.cache/kagglehub/datasets/dejolilandry/iemocapfullrelease/versions/1\n",
      "\n",
      "üîÑ Loading IEMOCAP dataset...\n",
      "üìÇ Scanning dataset directory: /root/.cache/kagglehub/datasets/dejolilandry/iemocapfullrelease/versions/1\n",
      "\n",
      "‚úÖ Collected 0 samples in total\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No samples found in dataset!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-2878087296.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Create train dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nüîÑ Loading IEMOCAP dataset...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCustomIEMOCAPDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_root\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCustomIEMOCAPDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_root\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/speech-emotion-recognition-25/dataset/custom_iemocap_dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset_root, split, train_ratio, seed, transform)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;31m# Split into train/test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/speech-emotion-recognition-25/dataset/custom_iemocap_dataset.py\u001b[0m in \u001b[0;36m_split_dataset\u001b[0;34m(self, session_train, session_val, session_test)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;34m\"\"\"Split dataset into train and test sets.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No samples found in dataset!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mtrain_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'session_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msession_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No samples found in dataset!"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from dataset.custom_iemocap_dataset import CustomIEMOCAPDataset\n",
    "import os\n",
    "\n",
    "# Detect environment and set dataset path automatically\n",
    "if os.path.exists('/root/.cache/kagglehub/datasets/dejolilandry/iemocapfullrelease/versions/1'):\n",
    "    # Running with kagglehub cache (local or Colab with kagglehub)\n",
    "    dataset_path = '/root/.cache/kagglehub/datasets/dejolilandry/iemocapfullrelease/versions/1'\n",
    "    print(\"‚úì Found IEMOCAP in kagglehub cache\")\n",
    "elif os.path.exists('/kaggle/input/iemocapfullrelease'):\n",
    "    # Running on Kaggle environment\n",
    "    dataset_path = '/kaggle/input/iemocapfullrelease'\n",
    "    print(\"‚úì Detected Kaggle environment\")\n",
    "else:\n",
    "    # Running locally or Colab\n",
    "    dataset_path = './data/'\n",
    "    print(\"‚úì Using local data path\")\n",
    "\n",
    "print(f\"üìÇ Using dataset path: {dataset_path}\")\n",
    "\n",
    "# Check if dataset exists\n",
    "if not os.path.exists(dataset_path):\n",
    "    print(f\"‚ö†Ô∏è Warning: Dataset path not found: {dataset_path}\")\n",
    "\n",
    "# Create train dataset\n",
    "print(\"\\nüîÑ Loading IEMOCAP dataset...\")\n",
    "train_dataset = CustomIEMOCAPDataset(dataset_root=dataset_path, split='train')\n",
    "test_dataset = CustomIEMOCAPDataset(dataset_root=dataset_path, split='test')\n",
    "\n",
    "print(f\"\\n‚úì Train samples: {len(train_dataset)}\")\n",
    "print(f\"‚úì Test samples: {len(test_dataset)}\")\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 4\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"\\n‚úì DataLoaders created!\")\n",
    "print(f\"  - Train batches: {len(train_dataloader)}\")\n",
    "print(f\"  - Test batches: {len(test_dataloader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils.visualization'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-176467943.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Visualize training samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualization\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvisualize_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_batch_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Visualizing samples from training set...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint_batch_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils.visualization'",
      "",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Visualize training samples\n",
    "from utils.visualization import visualize_samples, print_batch_info\n",
    "print(\"Visualizing samples from training set...\")\n",
    "batch = next(iter(train_dataloader))\n",
    "print_batch_info(batch)\n",
    "print(\"\\n\")\n",
    "visualize_samples(train_dataloader, num_samples=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sqo9Eh79yihI"
   },
   "source": [
    "# Step 4: Train your model and visualize training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4-dxDQOFcdgX"
   },
   "outputs": [],
   "source": [
    "#%env WANDB_API_KEY=\"7ade30086de7899bed412e3eb5c2da065c146f90\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "8q9OvEDHxmRv"
   },
   "outputs": [],
   "source": [
    "#!python train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DyQo3klIymlz"
   },
   "source": [
    "# Step 5: Evaluate your model\n",
    "\n",
    "1.   List item\n",
    "2.   List item\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9goKvp4jxk4j"
   },
   "outputs": [],
   "source": [
    "#!python eval.py"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
