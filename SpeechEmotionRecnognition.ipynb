{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-E9qeg-6y1Hu"
   },
   "source": [
    "# LAB 3: How to setup a project from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "XHmVt4s034WK"
   },
   "outputs": [],
   "source": [
    "!rm -rf speech-emotion-recognition-25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y6kJGhxzyN6d"
   },
   "source": [
    "# Step 1: Clone your project from Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Wfm084txMr0",
    "outputId": "91f0ad75-ff73-4cfb-b5f1-be42a8c96886"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'speech-emotion-recognition-25'...\n",
      "remote: Enumerating objects: 103, done.\u001b[K\n",
      "remote: Counting objects: 100% (92/92), done.\u001b[K\n",
      "remote: Compressing objects: 100% (70/70), done.\u001b[K\n",
      "remote: Total 103 (delta 46), reused 62 (delta 18), pack-reused 11 (from 2)\u001b[K\n",
      "Receiving objects: 100% (103/103), 32.05 KiB | 10.68 MiB/s, done.\n",
      "Resolving deltas: 100% (46/46), done.\n"
     ]
    }
   ],
   "source": [
    "#main\n",
    "#!git clone https://github.com/MatteoPaglia/speech-emotion-recognition-25.git\n",
    "\n",
    "#             nome branch\n",
    "\n",
    "!git clone -b DatasetSetup https://github.com/MatteoPaglia/speech-emotion-recognition-25.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MN0lMneJxVz0",
    "outputId": "64b85f65-94db-4b58-9b9b-1e41effc2001"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_data  speech-emotion-recognition-25\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Pa5nOPxxbDf",
    "outputId": "cb19573e-9b7e-42c0-abe3-92b4fc6493de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/speech-emotion-recognition-25\n"
     ]
    }
   ],
   "source": [
    "# %cd mldl_project_skeleton\n",
    "%cd speech-emotion-recognition-25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VYilllpZzKMz",
    "outputId": "21364bda-49b5-450d-b782-846928e1bdd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints  dataset  models\t requirements.txt\t\t  train.py\n",
      "data\t     eval.py  README.md  SpeechEmotionRecnognition.ipynb  utils\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "be_4yDyp1Hru"
   },
   "source": [
    "# Step 2: Packages Installation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "EO9DuAYk1LFR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (1.7.4.5)\n",
      "Requirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (0.3.13)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle->-r requirements.txt (line 1)) (6.3.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle->-r requirements.txt (line 1)) (2025.11.12)\n",
      "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle->-r requirements.txt (line 1)) (3.4.4)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle->-r requirements.txt (line 1)) (3.11)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle->-r requirements.txt (line 1)) (5.29.5)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle->-r requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle->-r requirements.txt (line 1)) (8.0.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle->-r requirements.txt (line 1)) (2.32.4)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle->-r requirements.txt (line 1)) (75.2.0)\n",
      "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle->-r requirements.txt (line 1)) (1.17.0)\n",
      "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle->-r requirements.txt (line 1)) (1.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kaggle->-r requirements.txt (line 1)) (4.67.1)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle->-r requirements.txt (line 1)) (2.5.0)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle->-r requirements.txt (line 1)) (0.5.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub->-r requirements.txt (line 2)) (25.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub->-r requirements.txt (line 2)) (6.0.3)\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bifSi62Ixrqr"
   },
   "source": [
    "# Step 3: Dataset Setup\n",
    "## Different options\n",
    "- First one is downloading using a script that places the data in the download folder (usually recommended)\n",
    "- Second one is uploading the dataset to your personal/institutional Google Drive and load it from there ([Read More](https://saturncloud.io/blog/google-colab-how-to-read-data-from-my-google-drive/))\n",
    "- Place the download script directly here on colab\n",
    "\n",
    "You are free to do as you please in this phase.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "DiWQTaTbxeIc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Configurazione Kaggle ---\n",
      "Kaggle configurato con successo.\n",
      "\n",
      "--- Download RAVDESS ---\n",
      "Contatto KaggleHub per scaricare: uwrfkaggler/ravdess-emotional-speech-audio...\n",
      "Using Colab cache for faster access to the 'ravdess-emotional-speech-audio' dataset.\n",
      "âœ“ Dataset scaricato nella cache di sistema: /kaggle/input/ravdess-emotional-speech-audio\n",
      "Copia dei file nella cartella di lavoro: ./ravdess...\n",
      "RAVDESS pronto in: ./ravdess\n",
      "Numero totale di file copiati: 2880\n",
      "\n",
      "--- Download IEMOCAP ---\n",
      "Contatto KaggleHub per scaricare: dejolilandry/iemocapfullrelease...\n",
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/dejolilandry/iemocapfullrelease?dataset_version_number=1...\n",
      "100% 11.5G/11.5G [02:09<00:00, 95.9MB/s]\n",
      "Extracting files...\n",
      "âœ“ Dataset scaricato nella cache di sistema: /root/.cache/kagglehub/datasets/dejolilandry/iemocapfullrelease/versions/1\n",
      "Inizio la copia selettiva (cercando: 'Impro')...\n",
      "IEMOCAP pronto in: ./iemocap\n",
      "Numero totale di file copiati: 37247\n",
      "\n",
      "============================================================\n",
      "RIEPILOGO DOWNLOAD\n",
      "============================================================\n",
      "RAVDESS: âœ… Successo\n",
      "IEMOCAP: âœ… Successo\n",
      "============================================================\n",
      "\n",
      "ðŸŽ‰ Tutti i dataset sono stati scaricati con successo!\n"
     ]
    }
   ],
   "source": [
    "!python utils/download_dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dirs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-1681592610.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Mostra TUTTE le directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mis_last_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{prefix}{'â””â”€â”€ ' if is_last_dir else 'â”œâ”€â”€ '}ðŸ“ {item.name}/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dirs' is not defined"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ESPLORAZIONE STRUTTURA DATASET (VERSIONE COMPLETA)\n",
    "# ============================================================================\n",
    "\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "def analyze_dataset_structure_detailed(dataset_path, dataset_name):\n",
    "    \"\"\"Analizza e mostra la struttura COMPLETA di un dataset\"\"\"\n",
    "    print(\"=\" * 100)\n",
    "    print(f\"ðŸ“ STRUTTURA DATASET COMPLETA: {dataset_name.upper()}\")\n",
    "    print(\"=\" * 100)\n",
    "    \n",
    "    path = Path(dataset_path)\n",
    "    \n",
    "    if not path.exists():\n",
    "        print(f\"âŒ Directory non trovata: {dataset_path}\")\n",
    "        return\n",
    "    \n",
    "    # 1. STATISTICHE GENERALI\n",
    "    print(\"\\nðŸ“Š STATISTICHE GENERALI:\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    total_files = 0\n",
    "    total_size = 0\n",
    "    file_extensions = defaultdict(int)\n",
    "    dir_count = 0\n",
    "    \n",
    "    for item in path.rglob('*'):\n",
    "        if item.is_file():\n",
    "            total_files += 1\n",
    "            total_size += item.stat().st_size\n",
    "            ext = item.suffix.lower() or '[no extension]'\n",
    "            file_extensions[ext] += 1\n",
    "        elif item.is_dir():\n",
    "            dir_count += 1\n",
    "    \n",
    "    print(f\"  â€¢ Totale cartelle: {dir_count}\")\n",
    "    print(f\"  â€¢ Totale file: {total_files}\")\n",
    "    print(f\"  â€¢ Dimensione totale: {total_size / (1024**3):.2f} GB\")\n",
    "    print(f\"  â€¢ Tipi di file:\")\n",
    "    for ext, count in sorted(file_extensions.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"      {ext}: {count} file(s)\")\n",
    "    \n",
    "    # 2. ALBERO COMPLETO DELLE DIRECTORY\n",
    "    print(\"\\nðŸ“‚ ALBERO COMPLETO DELLE CARTELLE:\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    def print_tree_complete(directory, prefix=\"\", max_depth=10, current_depth=0):\n",
    "        \"\"\"Stampa l'intero albero senza limitazioni\"\"\"\n",
    "        if current_depth >= max_depth:\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            items = sorted(directory.iterdir(), key=lambda x: (not x.is_dir(), x.name))\n",
    "            dirs = [item for item in items if item.is_dir()]\n",
    "            files = [item for item in items if item.is_file()]\n",
    "            \n",
    "            # Mostra TUTTE le directory\n",
    "            for i, item in enumerate(dirs):\n",
    "                is_last_dir = (i == len(dirs) - 1) and len(files) == 0\n",
    "                print(f\"{prefix}{'â””â”€â”€ ' if is_last_dir else 'â”œâ”€â”€ '}ðŸ“ {item.name}/\")\n",
    "                \n",
    "                extension = \"    \" if is_last_dir else \"â”‚   \"\n",
    "                print_tree_complete(item, prefix + extension, max_depth, current_depth + 1)\n",
    "            \n",
    "            \n",
    "        except PermissionError:\n",
    "            print(f\"{prefix}âŒ Accesso negato\")\n",
    "    \n",
    "    print_tree_complete(path)\n",
    "    \n",
    "    # 3. ELENCO DIRECTORY PER LIVELLO\n",
    "    print(\"\\n\\nðŸ“Š GERARCHIA DIRECTORY PER LIVELLO:\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    level_dirs = defaultdict(list)\n",
    "    for item in path.rglob('*'):\n",
    "        if item.is_dir():\n",
    "            depth = len(item.relative_to(path).parts)\n",
    "            relative_path = item.relative_to(path)\n",
    "            level_dirs[depth].append(str(relative_path))\n",
    "    \n",
    "    for level in sorted(level_dirs.keys()):\n",
    "        print(f\"\\nðŸ”¹ Livello {level} ({len(level_dirs[level])} cartelle):\")\n",
    "        for dir_path in sorted(level_dirs[level])[:20]:  # Mostra prime 20\n",
    "            print(f\"     â€¢ {dir_path}\")\n",
    "        if len(level_dirs[level]) > 20:\n",
    "            print(f\"     ... e altri {len(level_dirs[level]) - 20} directory\")\n",
    "    \n",
    "    # 4. CONTENUTO DETTAGLIATO PER SESSION (SE IEMOCAP)\n",
    "    if \"iemocap\" in dataset_name.lower():\n",
    "        print(\"\\n\\nðŸŽ™ï¸ DETTAGLI IEMOCAP - CONTENUTO PER SESSION:\")\n",
    "        print(\"-\" * 100)\n",
    "        \n",
    "        sessions = sorted([d for d in path.iterdir() if d.is_dir() and d.name.startswith(\"Session\")])\n",
    "        for session in sessions:\n",
    "            print(f\"\\n  {session.name}:\")\n",
    "            subdirs = sorted([d for d in session.iterdir() if d.is_dir()])\n",
    "            for subdir in subdirs:\n",
    "                file_count = len(list(subdir.glob('*')))\n",
    "                print(f\"    â”œâ”€â”€ {subdir.name}/ ({file_count} items)\")\n",
    "                # Mostra alcuni file esempi\n",
    "                sample_files = list(subdir.glob('*'))[:5]\n",
    "                for f in sample_files:\n",
    "                    if f.is_file():\n",
    "                        size = f.stat().st_size / (1024**2) if f.stat().st_size > 1024**2 else f.stat().st_size / 1024\n",
    "                        size_unit = \"MB\" if f.stat().st_size > 1024**2 else \"KB\"\n",
    "                        print(f\"    â”‚   â”œâ”€â”€ {f.name} ({size:.2f} {size_unit})\")\n",
    "                    else:\n",
    "                        print(f\"    â”‚   â”œâ”€â”€ {f.name}/\")\n",
    "                if len(sample_files) < file_count:\n",
    "                    print(f\"    â”‚   â””â”€â”€ ... altri {file_count - len(sample_files)} items\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 100 + \"\\n\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# ANALISI RAVDESS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"ðŸŽµ\" * 40)\n",
    "print(\"ANALISI DATASET RAVDESS\")\n",
    "print(\"ðŸŽµ\" * 40 + \"\\n\")\n",
    "\n",
    "analyze_dataset_structure_detailed(\"./ravdess\", \"RAVDESS\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# ANALISI IEMOCAP\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"ðŸŽ™ï¸\" * 40)\n",
    "print(\"ANALISI DATASET IEMOCAP\")\n",
    "print(\"ðŸŽ™ï¸\" * 40 + \"\\n\")\n",
    "\n",
    "analyze_dataset_structure_detailed(\"./iemocap\", \"IEMOCAP\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3.5: Improvised Vocal Recording\n",
    "\n",
    "Model IEMOCAP dataset to extract only improvised audio. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## insert code here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sqo9Eh79yihI"
   },
   "source": [
    "# Step 4: Train your model and visualize training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "4-dxDQOFcdgX"
   },
   "outputs": [],
   "source": [
    "#%env WANDB_API_KEY=\"7ade30086de7899bed412e3eb5c2da065c146f90\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "id": "8q9OvEDHxmRv"
   },
   "outputs": [],
   "source": [
    "#!python train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DyQo3klIymlz"
   },
   "source": [
    "# Step 5: Evaluate your model\n",
    "\n",
    "1.   List item\n",
    "2.   List item\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "9goKvp4jxk4j"
   },
   "outputs": [],
   "source": [
    "#!python eval.py"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
