{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-E9qeg-6y1Hu"
   },
   "source": [
    "# LAB 3: How to setup a project from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "XHmVt4s034WK"
   },
   "outputs": [],
   "source": [
    "!rm -rf speech-emotion-recognition-25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y6kJGhxzyN6d"
   },
   "source": [
    "# Step 1: Clone your project from Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Wfm084txMr0",
    "outputId": "91f0ad75-ff73-4cfb-b5f1-be42a8c96886"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'speech-emotion-recognition-25'...\n",
      "remote: Enumerating objects: 166, done.\u001b[K\n",
      "remote: Counting objects: 100% (72/72), done.\u001b[K\n",
      "remote: Compressing objects: 100% (49/49), done.\u001b[K\n",
      "remote: Total 166 (delta 49), reused 41 (delta 21), pack-reused 94 (from 3)\u001b[K\n",
      "Receiving objects: 100% (166/166), 59.51 KiB | 1.12 MiB/s, done.\n",
      "Resolving deltas: 100% (85/85), done.\n"
     ]
    }
   ],
   "source": [
    "#main\n",
    "#!git clone https://github.com/MatteoPaglia/speech-emotion-recognition-25.git\n",
    "\n",
    "#             nome branch\n",
    "\n",
    "!git clone -b RavdnessClass https://github.com/MatteoPaglia/speech-emotion-recognition-25.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MN0lMneJxVz0",
    "outputId": "64b85f65-94db-4b58-9b9b-1e41effc2001"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_data  speech-emotion-recognition-25\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Pa5nOPxxbDf",
    "outputId": "cb19573e-9b7e-42c0-abe3-92b4fc6493de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/speech-emotion-recognition-25\n"
     ]
    }
   ],
   "source": [
    "# %cd mldl_project_skeleton\n",
    "%cd speech-emotion-recognition-25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VYilllpZzKMz",
    "outputId": "21364bda-49b5-450d-b782-846928e1bdd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints  dataset  models\t requirements.txt\t\t  train.py\n",
      "data\t     eval.py  README.md  SpeechEmotionRecnognition.ipynb  utils\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "be_4yDyp1Hru"
   },
   "source": [
    "# Step 2: Packages Installation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "EO9DuAYk1LFR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (1.7.4.5)\n",
      "Requirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (0.3.13)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (1.6.1)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle->-r requirements.txt (line 1)) (6.3.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle->-r requirements.txt (line 1)) (2025.11.12)\n",
      "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle->-r requirements.txt (line 1)) (3.4.4)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle->-r requirements.txt (line 1)) (3.11)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle->-r requirements.txt (line 1)) (5.29.5)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle->-r requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle->-r requirements.txt (line 1)) (8.0.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle->-r requirements.txt (line 1)) (2.32.4)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle->-r requirements.txt (line 1)) (75.2.0)\n",
      "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle->-r requirements.txt (line 1)) (1.17.0)\n",
      "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle->-r requirements.txt (line 1)) (1.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kaggle->-r requirements.txt (line 1)) (4.67.1)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle->-r requirements.txt (line 1)) (2.5.0)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle->-r requirements.txt (line 1)) (0.5.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub->-r requirements.txt (line 2)) (25.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub->-r requirements.txt (line 2)) (6.0.3)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements.txt (line 3)) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements.txt (line 3)) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements.txt (line 3)) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements.txt (line 3)) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bifSi62Ixrqr"
   },
   "source": [
    "# Step 3: Dataset Setup\n",
    "## Different options\n",
    "- First one is downloading using a script that places the data in the download folder (usually recommended)\n",
    "- Second one is uploading the dataset to your personal/institutional Google Drive and load it from there ([Read More](https://saturncloud.io/blog/google-colab-how-to-read-data-from-my-google-drive/))\n",
    "- Place the download script directly here on colab\n",
    "\n",
    "You are free to do as you please in this phase.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "DiWQTaTbxeIc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚¨áÔ∏è  Download dataset in corso...\n",
      "--- 1. Configurazione Kaggle ---\n",
      "Kaggle configurato con successo.\n",
      "\n",
      "--- Download RAVDESS ---\n",
      "Contatto KaggleHub per scaricare: uwrfkaggler/ravdess-emotional-speech-audio...\n",
      "Using Colab cache for faster access to the 'ravdess-emotional-speech-audio' dataset.\n",
      "‚úì Dataset scaricato nella cache di sistema: /kaggle/input/ravdess-emotional-speech-audio\n",
      "Copia dei file nella cartella di lavoro: ./ravdess...\n",
      "RAVDESS pronto in: ./ravdess\n",
      "Numero totale di file copiati: 2880\n",
      "\n",
      "--- Download IEMOCAP ---\n",
      "Contatto KaggleHub per scaricare: dejolilandry/iemocapfullrelease...\n",
      "Using Colab cache for faster access to the 'iemocapfullrelease' dataset.\n",
      "‚úì Dataset scaricato nella cache di sistema: /kaggle/input/iemocapfullrelease\n",
      "Inizio la copia selettiva (cercando: 'Impro')...\n",
      "IEMOCAP pronto in: ./iemocap\n",
      "Numero totale di file copiati: 37247\n",
      "\n",
      "============================================================\n",
      "RIEPILOGO DOWNLOAD\n",
      "============================================================\n",
      "RAVDESS: ‚úÖ Successo\n",
      "IEMOCAP: ‚úÖ Successo\n",
      "============================================================\n",
      "\n",
      "üéâ Tutti i dataset sono stati scaricati con successo!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SMART DATASET DOWNLOAD - Scarica solo se non presente\n",
    "# ============================================================================\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "ravdess_path = Path('./ravdess')\n",
    "iemocap_path = Path('./iemocap')\n",
    "\n",
    "# Verifica se i dataset esistono gi√†\n",
    "ravdess_exists = ravdess_path.exists() and any(ravdess_path.iterdir())\n",
    "iemocap_exists = iemocap_path.exists() and any(iemocap_path.iterdir())\n",
    "\n",
    "if ravdess_exists and iemocap_exists:\n",
    "    print(\"‚úÖ Dataset gi√† presenti, skip download\")\n",
    "    print(f\"   üìÅ RAVDESS: {ravdess_path}\")\n",
    "    print(f\"   üìÅ IEMOCAP: {iemocap_path}\")\n",
    "else:\n",
    "    print(\"‚¨áÔ∏è  Download dataset in corso...\")\n",
    "    !python utils/download_dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéµüéµüéµüéµüéµüéµüéµüéµüéµüéµüéµüéµüéµüéµüéµüéµüéµüéµüéµüéµüéµüéµüéµüéµüéµüéµüéµüéµüéµüéµüéµüéµüéµüéµüéµüéµüéµüéµüéµüéµ\n",
      "ANALISI DATASET RAVDESS\n",
      "üéµüéµüéµüéµüéµüéµüéµüéµüéµüéµüéµüéµüéµüéµüéµüéµüéµüéµüéµüéµüéµüéµüéµüéµüéµüéµüéµüéµüéµüéµüéµüéµüéµüéµüéµüéµüéµüéµüéµüéµ\n",
      "\n",
      "================================================================================\n",
      "üìÅ STRUTTURA DATASET: RAVDESS\n",
      "================================================================================\n",
      "\n",
      "üìä STATISTICHE GENERALI:\n",
      "--------------------------------------------------------------------------------\n",
      "  ‚Ä¢ Totale file: 2880\n",
      "  ‚Ä¢ Dimensione totale: 1.10 GB\n",
      "  ‚Ä¢ Tipi di file:\n",
      "      .wav: 2880 file(s)\n",
      "\n",
      "üìÇ STRUTTURA DIRECTORY (primi 3 livelli):\n",
      "--------------------------------------------------------------------------------\n",
      "‚îú‚îÄ‚îÄ üìÅ Actor_01/\n",
      "‚îÇ   ‚îú‚îÄ‚îÄ üìÑ 03-01-01-01-01-01-01.wav (0.36 MB)\n",
      "‚îÇ   ‚îú‚îÄ‚îÄ üìÑ 03-01-01-01-01-02-01.wav (0.36 MB)\n",
      "‚îÇ   ‚îî‚îÄ‚îÄ üìÑ 03-01-01-01-02-01-01.wav (0.36 MB)\n",
      "‚îÇ   ‚îî‚îÄ‚îÄ ... altri 57 file\n",
      "‚îú‚îÄ‚îÄ üìÅ Actor_02/\n",
      "‚îÇ   ‚îú‚îÄ‚îÄ üìÑ 03-01-01-01-01-01-02.wav (0.39 MB)\n",
      "‚îÇ   ‚îú‚îÄ‚îÄ üìÑ 03-01-01-01-01-02-02.wav (0.39 MB)\n",
      "‚îÇ   ‚îî‚îÄ‚îÄ üìÑ 03-01-01-01-02-01-02.wav (0.40 MB)\n",
      "‚îÇ   ‚îî‚îÄ‚îÄ ... altri 57 file\n",
      "‚îî‚îÄ‚îÄ üìÅ Actor_03/\n",
      "    ‚îú‚îÄ‚îÄ üìÑ 03-01-01-01-01-01-03.wav (0.36 MB)\n",
      "    ‚îú‚îÄ‚îÄ üìÑ 03-01-01-01-01-02-03.wav (0.37 MB)\n",
      "    ‚îî‚îÄ‚îÄ üìÑ 03-01-01-01-02-01-03.wav (0.37 MB)\n",
      "    ‚îî‚îÄ‚îÄ ... altri 57 file\n",
      "‚îî‚îÄ‚îÄ ... altre 22 cartelle\n",
      "\n",
      "üìù ESEMPIO PERCORSI FILE (primi 5):\n",
      "--------------------------------------------------------------------------------\n",
      "  ‚Ä¢ Actor_04/03-01-05-02-02-02-04.wav\n",
      "    Dimensione: 0.41 MB\n",
      "  ‚Ä¢ Actor_04/03-01-08-02-02-02-04.wav\n",
      "    Dimensione: 0.38 MB\n",
      "  ‚Ä¢ Actor_04/03-01-03-01-02-01-04.wav\n",
      "    Dimensione: 0.38 MB\n",
      "  ‚Ä¢ Actor_04/03-01-05-01-01-02-04.wav\n",
      "    Dimensione: 0.38 MB\n",
      "  ‚Ä¢ Actor_04/03-01-02-01-02-02-04.wav\n",
      "    Dimensione: 0.38 MB\n",
      "\n",
      "üìä DISTRIBUZIONE FILE PER LIVELLO:\n",
      "--------------------------------------------------------------------------------\n",
      "  Livello 1: 1440 file(s)\n",
      "  Livello 2: 1440 file(s)\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "üéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏è\n",
      "ANALISI DATASET IEMOCAP\n",
      "üéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏èüéôÔ∏è\n",
      "\n",
      "================================================================================\n",
      "üìÅ STRUTTURA DATASET: IEMOCAP\n",
      "================================================================================\n",
      "\n",
      "üìä STATISTICHE GENERALI:\n",
      "--------------------------------------------------------------------------------\n",
      "  ‚Ä¢ Totale file: 37247\n",
      "  ‚Ä¢ Dimensione totale: 4.73 GB\n",
      "  ‚Ä¢ Tipi di file:\n",
      "      .txt: 13333 file(s)\n",
      "      .wav: 4784 file(s)\n",
      "      .wdseg: 4782 file(s)\n",
      "      .stseg: 4782 file(s)\n",
      "      .syseg: 4782 file(s)\n",
      "      .phseg: 4782 file(s)\n",
      "      .pk: 2 file(s)\n",
      "\n",
      "üìÇ STRUTTURA DIRECTORY (primi 3 livelli):\n",
      "--------------------------------------------------------------------------------\n",
      "‚îî‚îÄ‚îÄ üìÅ IEMOCAP_full_release/\n",
      "    ‚îú‚îÄ‚îÄ üìÅ Session1/\n",
      "    ‚îÇ   ‚îî‚îÄ‚îÄ üìÅ sentences/\n",
      "    ‚îú‚îÄ‚îÄ üìÅ Session2/\n",
      "    ‚îÇ   ‚îî‚îÄ‚îÄ üìÅ sentences/\n",
      "    ‚îî‚îÄ‚îÄ üìÅ Session3/\n",
      "        ‚îî‚îÄ‚îÄ üìÅ sentences/\n",
      "    ‚îî‚îÄ‚îÄ ... altre 2 cartelle\n",
      "\n",
      "üìù ESEMPIO PERCORSI FILE (primi 5):\n",
      "--------------------------------------------------------------------------------\n",
      "  ‚Ä¢ IEMOCAP_full_release/Session5/sentences/MOCAP_head/Ses05F_impro02/Ses05F_impro02_M020.txt\n",
      "    Dimensione: 0.03 MB\n",
      "  ‚Ä¢ IEMOCAP_full_release/Session5/sentences/MOCAP_head/Ses05F_impro02/Ses05F_impro02_M023.txt\n",
      "    Dimensione: 0.05 MB\n",
      "  ‚Ä¢ IEMOCAP_full_release/Session5/sentences/MOCAP_head/Ses05F_impro02/Ses05F_impro02_F010.txt\n",
      "    Dimensione: 0.09 MB\n",
      "  ‚Ä¢ IEMOCAP_full_release/Session5/sentences/MOCAP_head/Ses05F_impro02/Ses05F_impro02_M027.txt\n",
      "    Dimensione: 0.03 MB\n",
      "  ‚Ä¢ IEMOCAP_full_release/Session5/sentences/MOCAP_head/Ses05F_impro02/Ses05F_impro02_F015.txt\n",
      "    Dimensione: 0.03 MB\n",
      "\n",
      "üìä DISTRIBUZIONE FILE PER LIVELLO:\n",
      "--------------------------------------------------------------------------------\n",
      "  Livello 5: 37247 file(s)\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ESPLORAZIONE STRUTTURA DATASET\n",
    "# ============================================================================\n",
    "\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "def analyze_dataset_structure(dataset_path, dataset_name):\n",
    "    \"\"\"Analizza e mostra la struttura di un dataset\"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"üìÅ STRUTTURA DATASET: {dataset_name.upper()}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    path = Path(dataset_path)\n",
    "    \n",
    "    if not path.exists():\n",
    "        print(f\"‚ùå Directory non trovata: {dataset_path}\")\n",
    "        return\n",
    "    \n",
    "    # 1. STATISTICHE GENERALI\n",
    "    print(\"\\nüìä STATISTICHE GENERALI:\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    total_files = 0\n",
    "    total_size = 0\n",
    "    file_extensions = defaultdict(int)\n",
    "    \n",
    "    for item in path.rglob('*'):\n",
    "        if item.is_file():\n",
    "            total_files += 1\n",
    "            total_size += item.stat().st_size\n",
    "            ext = item.suffix.lower() or '[no extension]'\n",
    "            file_extensions[ext] += 1\n",
    "    \n",
    "    print(f\"  ‚Ä¢ Totale file: {total_files}\")\n",
    "    print(f\"  ‚Ä¢ Dimensione totale: {total_size / (1024**3):.2f} GB\")\n",
    "    print(f\"  ‚Ä¢ Tipi di file:\")\n",
    "    for ext, count in sorted(file_extensions.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"      {ext}: {count} file(s)\")\n",
    "    \n",
    "    # 2. STRUTTURA DIRECTORY (primi 3 livelli)\n",
    "    print(\"\\nüìÇ STRUTTURA DIRECTORY (primi 3 livelli):\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    def print_tree(directory, prefix=\"\", max_depth=3, current_depth=0):\n",
    "        if current_depth >= max_depth:\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            items = sorted(directory.iterdir(), key=lambda x: (not x.is_dir(), x.name))\n",
    "            dirs = [item for item in items if item.is_dir()]\n",
    "            files = [item for item in items if item.is_file()]\n",
    "            \n",
    "            # Mostra prime 3 directory\n",
    "            for i, item in enumerate(dirs[:3]):\n",
    "                is_last = (i == len(dirs[:3]) - 1) and len(files) == 0\n",
    "                print(f\"{prefix}{'‚îî‚îÄ‚îÄ ' if is_last else '‚îú‚îÄ‚îÄ '}üìÅ {item.name}/\")\n",
    "                \n",
    "                extension = \"    \" if is_last else \"‚îÇ   \"\n",
    "                print_tree(item, prefix + extension, max_depth, current_depth + 1)\n",
    "            \n",
    "            if len(dirs) > 3:\n",
    "                print(f\"{prefix}‚îî‚îÄ‚îÄ ... altre {len(dirs) - 3} cartelle\")\n",
    "            \n",
    "            # Mostra primi 3 file\n",
    "            if files and current_depth < max_depth - 1:\n",
    "                for i, item in enumerate(files[:3]):\n",
    "                    is_last = i == len(files[:3]) - 1\n",
    "                    size_mb = item.stat().st_size / (1024**2)\n",
    "                    print(f\"{prefix}{'‚îî‚îÄ‚îÄ ' if is_last else '‚îú‚îÄ‚îÄ '}üìÑ {item.name} ({size_mb:.2f} MB)\")\n",
    "                \n",
    "                if len(files) > 3:\n",
    "                    print(f\"{prefix}‚îî‚îÄ‚îÄ ... altri {len(files) - 3} file\")\n",
    "        \n",
    "        except PermissionError:\n",
    "            print(f\"{prefix}‚ùå Accesso negato\")\n",
    "    \n",
    "    print_tree(path)\n",
    "    \n",
    "    # 3. ESEMPIO FILE PATHS (primi 5)\n",
    "    print(\"\\nüìù ESEMPIO PERCORSI FILE (primi 5):\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    all_files = list(path.rglob('*'))\n",
    "    file_list = [f for f in all_files if f.is_file()][:5]\n",
    "    \n",
    "    for f in file_list:\n",
    "        relative_path = f.relative_to(path)\n",
    "        size_mb = f.stat().st_size / (1024**2)\n",
    "        print(f\"  ‚Ä¢ {relative_path}\")\n",
    "        print(f\"    Dimensione: {size_mb:.2f} MB\")\n",
    "    \n",
    "    # 4. DISTRIBUZIONE PER LIVELLO\n",
    "    print(\"\\nüìä DISTRIBUZIONE FILE PER LIVELLO:\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    level_distribution = defaultdict(int)\n",
    "    for item in path.rglob('*'):\n",
    "        if item.is_file():\n",
    "            depth = len(item.relative_to(path).parts) - 1\n",
    "            level_distribution[depth] += 1\n",
    "    \n",
    "    for level in sorted(level_distribution.keys()):\n",
    "        print(f\"  Livello {level}: {level_distribution[level]} file(s)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80 + \"\\n\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# ANALISI RAVDESS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"üéµ\" * 40)\n",
    "print(\"ANALISI DATASET RAVDESS\")\n",
    "print(\"üéµ\" * 40 + \"\\n\")\n",
    "\n",
    "analyze_dataset_structure(\"./ravdess\", \"RAVDESS\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# ANALISI IEMOCAP\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"üéôÔ∏è\" * 40)\n",
    "print(\"ANALISI DATASET IEMOCAP\")\n",
    "print(\"üéôÔ∏è\" * 40 + \"\\n\")\n",
    "\n",
    "analyze_dataset_structure(\"./iemocap\", \"IEMOCAP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3.5: Improvised Vocal Recording\n",
    "\n",
    "Model IEMOCAP dataset to extract only improvised audio. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## insert code here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Data Loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3.6: Test Ravdness \n",
    "\n",
    "Test Ravdness dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üß™ TEST DATASET RAVDESS - TRAIN/VALIDATION/TEST SPLIT\n",
      "================================================================================\n",
      "\n",
      "üì¶ Inizializzazione datasets...\n",
      "--------------------------------------------------------------------------------\n",
      "üîç Trovati 2880 file audio totali nel dataset\n",
      "‚úÖ Dopo i filtri: 1344 samples validi\n",
      "   - Audio-only (modality 03)\n",
      "   - Speech-only (vocal_channel 01)\n",
      "   - Emotions: ['neutral', 'happy', 'sad', 'angry']\n",
      "üìä Totale campioni: 1344\n",
      "üìä Totale attori disponibili: 24\n",
      "\n",
      "üîÄ Split fisso predefinito:\n",
      "   Train:      Actors 01-20 (10M+10F) ‚Üí 1120 campioni (83.3%)\n",
      "   Validation: Actors 21-22 (1M+1F) ‚Üí 112 campioni (8.3%)\n",
      "   Test:       Actors 23-24 (1M+1F) ‚Üí 112 campioni (8.3%)\n",
      "\n",
      "üë• Attori assegnati:\n",
      "   Train:      [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
      "   Validation: [21, 22]\n",
      "   Test:       [23, 24]\n",
      "‚úÖ Dataset initialized: 1120 train samples\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "üîç Trovati 2880 file audio totali nel dataset\n",
      "‚úÖ Dopo i filtri: 1344 samples validi\n",
      "   - Audio-only (modality 03)\n",
      "   - Speech-only (vocal_channel 01)\n",
      "   - Emotions: ['neutral', 'happy', 'sad', 'angry']\n",
      "üìä Totale campioni: 1344\n",
      "üìä Totale attori disponibili: 24\n",
      "\n",
      "üîÄ Split fisso predefinito:\n",
      "   Train:      Actors 01-20 (10M+10F) ‚Üí 1120 campioni (83.3%)\n",
      "   Validation: Actors 21-22 (1M+1F) ‚Üí 112 campioni (8.3%)\n",
      "   Test:       Actors 23-24 (1M+1F) ‚Üí 112 campioni (8.3%)\n",
      "\n",
      "üë• Attori assegnati:\n",
      "   Train:      [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
      "   Validation: [21, 22]\n",
      "   Test:       [23, 24]\n",
      "‚úÖ Dataset initialized: 112 validation samples\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "üîç Trovati 2880 file audio totali nel dataset\n",
      "‚úÖ Dopo i filtri: 1344 samples validi\n",
      "   - Audio-only (modality 03)\n",
      "   - Speech-only (vocal_channel 01)\n",
      "   - Emotions: ['neutral', 'happy', 'sad', 'angry']\n",
      "üìä Totale campioni: 1344\n",
      "üìä Totale attori disponibili: 24\n",
      "\n",
      "üîÄ Split fisso predefinito:\n",
      "   Train:      Actors 01-20 (10M+10F) ‚Üí 1120 campioni (83.3%)\n",
      "   Validation: Actors 21-22 (1M+1F) ‚Üí 112 campioni (8.3%)\n",
      "   Test:       Actors 23-24 (1M+1F) ‚Üí 112 campioni (8.3%)\n",
      "\n",
      "üë• Attori assegnati:\n",
      "   Train:      [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
      "   Validation: [21, 22]\n",
      "   Test:       [23, 24]\n",
      "‚úÖ Dataset initialized: 112 test samples\n",
      "\n",
      "================================================================================\n",
      "üìä STATISTICHE DATASET\n",
      "================================================================================\n",
      "\n",
      "üìà Numero di samples:\n",
      "   Train:      1120 samples ( 83.3%)\n",
      "   Validation:  112 samples (  8.3%)\n",
      "   Test:        112 samples (  8.3%)\n",
      "   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "   Totale:     1344 samples\n",
      "\n",
      "================================================================================\n",
      "üé≠ DISTRIBUZIONE EMOZIONI\n",
      "================================================================================\n",
      "\n",
      "TRAIN:\n",
      "   angry     : 320 samples ( 28.6%) ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   happy     : 320 samples ( 28.6%) ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   neutral   : 160 samples ( 14.3%) ‚ñà‚ñà\n",
      "   sad       : 320 samples ( 28.6%) ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "VALIDATION:\n",
      "   angry     :  32 samples ( 28.6%) ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   happy     :  32 samples ( 28.6%) ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   neutral   :  16 samples ( 14.3%) ‚ñà‚ñà\n",
      "   sad       :  32 samples ( 28.6%) ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "TEST:\n",
      "   angry     :  32 samples ( 28.6%) ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   happy     :  32 samples ( 28.6%) ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   neutral   :  16 samples ( 14.3%) ‚ñà‚ñà\n",
      "   sad       :  32 samples ( 28.6%) ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "================================================================================\n",
      "üîç VERIFICA SPEAKER-INDEPENDENT SPLIT\n",
      "================================================================================\n",
      "\n",
      "üë• Attori per set:\n",
      "   Train (20 attori):      [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
      "   Validation (2 attori):   [21, 22]\n",
      "   Test (2 attori):        [23, 24]\n",
      "\n",
      "üîé Verifica overlap attori:\n",
      "   ‚úÖ NESSUN OVERLAP! Split speaker-independent corretto!\n",
      "\n",
      "================================================================================\n",
      "üë®üë© VERIFICA BILANCIAMENTO GENERE\n",
      "================================================================================\n",
      "\n",
      "Train:\n",
      "   üë® Maschi:  10 attori ‚Üí [1, 3, 5, 7, 9, 11, 13, 15, 17, 19]\n",
      "   üë© Femmine: 10 attori ‚Üí [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n",
      "   Ratio: 10M / 10F\n",
      "\n",
      "Validation:\n",
      "   üë® Maschi:  1 attori ‚Üí [21]\n",
      "   üë© Femmine: 1 attori ‚Üí [22]\n",
      "   Ratio: 1M / 1F\n",
      "\n",
      "Test:\n",
      "   üë® Maschi:  1 attori ‚Üí [23]\n",
      "   üë© Femmine: 1 attori ‚Üí [24]\n",
      "   Ratio: 1M / 1F\n",
      "\n",
      "================================================================================\n",
      "üîç VERIFICA FILTRI SU CAMPIONI CASUALI\n",
      "================================================================================\n",
      "\n",
      "üìã Verifica su 5 samples casuali dal training set:\n",
      "\n",
      "  ‚úÖ Sample 1 (index 228):\n",
      "     üìÑ File: 03-01-04-01-02-01-14.wav\n",
      "     üé¨ Modality: 03 ‚úì\n",
      "     üé§ Vocal: 01 ‚úì\n",
      "     üòä Emotion: 04 (sad) ‚úì\n",
      "     üë§ Actor: 14 (F)\n",
      "     üí™ Intensity: 01\n",
      "\n",
      "  ‚úÖ Sample 2 (index 51):\n",
      "     üìÑ File: 03-01-01-01-02-02-03.wav\n",
      "     üé¨ Modality: 03 ‚úì\n",
      "     üé§ Vocal: 01 ‚úì\n",
      "     üòä Emotion: 01 (neutral) ‚úì\n",
      "     üë§ Actor: 03 (M)\n",
      "     üí™ Intensity: 01\n",
      "\n",
      "  ‚úÖ Sample 3 (index 563):\n",
      "     üìÑ File: 03-01-01-01-01-01-04.wav\n",
      "     üé¨ Modality: 03 ‚úì\n",
      "     üé§ Vocal: 01 ‚úì\n",
      "     üòä Emotion: 01 (neutral) ‚úì\n",
      "     üë§ Actor: 04 (F)\n",
      "     üí™ Intensity: 01\n",
      "\n",
      "  ‚úÖ Sample 4 (index 501):\n",
      "     üìÑ File: 03-01-03-01-02-02-01.wav\n",
      "     üé¨ Modality: 03 ‚úì\n",
      "     üé§ Vocal: 01 ‚úì\n",
      "     üòä Emotion: 03 (happy) ‚úì\n",
      "     üë§ Actor: 01 (M)\n",
      "     üí™ Intensity: 01\n",
      "\n",
      "  ‚úÖ Sample 5 (index 457):\n",
      "     üìÑ File: 03-01-04-02-02-02-02.wav\n",
      "     üé¨ Modality: 03 ‚úì\n",
      "     üé§ Vocal: 01 ‚úì\n",
      "     üòä Emotion: 04 (sad) ‚úì\n",
      "     üë§ Actor: 02 (F)\n",
      "     üí™ Intensity: 02\n",
      "\n",
      "================================================================================\n",
      "‚úÖ RIEPILOGO FINALE\n",
      "================================================================================\n",
      "\n",
      "   ‚úÖ Nessun overlap attori\n",
      "   ‚úÖ Tutti i filtri corretti\n",
      "   ‚úÖ 4 emozioni presenti\n",
      "   ‚úÖ Train: attori 1-20\n",
      "   ‚úÖ Validation: attori 21-22\n",
      "   ‚úÖ Test: attori 23-24\n",
      "\n",
      "================================================================================\n",
      "üéâ TUTTI I TEST SUPERATI! Dataset pronto per il training!\n",
      "üìä Split: 1120 train, 112 val, 112 test\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# TEST CUSTOM RAVDESS DATASET - TRAIN/VALIDATION/TEST SPLIT\n",
    "# ============================================================================\n",
    "\n",
    "from dataset.custom_ravdess_dataset import CustomRAVDESSDataset\n",
    "from collections import Counter\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"üß™ TEST DATASET RAVDESS - TRAIN/VALIDATION/TEST SPLIT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. Inizializza i tre dataset (SENZA validation_ratio, test_ratio, seed)\n",
    "print(\"\\nüì¶ Inizializzazione datasets...\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "train_dataset = CustomRAVDESSDataset(\n",
    "    dataset_root='./ravdess',\n",
    "    split='train'\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "\n",
    "val_dataset = CustomRAVDESSDataset(\n",
    "    dataset_root='./ravdess',\n",
    "    split='validation'\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "\n",
    "test_dataset = CustomRAVDESSDataset(\n",
    "    dataset_root='./ravdess',\n",
    "    split='test'\n",
    ")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STATISTICHE GENERALI\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìä STATISTICHE DATASET\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "total_samples = len(train_dataset) + len(val_dataset) + len(test_dataset)\n",
    "\n",
    "print(f\"\\nüìà Numero di samples:\")\n",
    "print(f\"   Train:      {len(train_dataset):4d} samples ({len(train_dataset)/total_samples*100:5.1f}%)\")\n",
    "print(f\"   Validation: {len(val_dataset):4d} samples ({len(val_dataset)/total_samples*100:5.1f}%)\")\n",
    "print(f\"   Test:       {len(test_dataset):4d} samples ({len(test_dataset)/total_samples*100:5.1f}%)\")\n",
    "print(f\"   {'‚îÄ'*50}\")\n",
    "print(f\"   Totale:     {total_samples:4d} samples\")\n",
    "\n",
    "# ============================================================================\n",
    "# DISTRIBUZIONE EMOZIONI\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üé≠ DISTRIBUZIONE EMOZIONI\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for name, dataset in [('TRAIN', train_dataset), ('VALIDATION', val_dataset), ('TEST', test_dataset)]:\n",
    "    print(f\"\\n{name}:\")\n",
    "    emotions = [s['metadata']['emotion_label'] for s in dataset.samples]\n",
    "    distribution = Counter(emotions)\n",
    "    \n",
    "    for emotion in sorted(CustomRAVDESSDataset.EMOTION_DICT.values()):\n",
    "        count = distribution.get(emotion, 0)\n",
    "        percentage = (count / len(dataset)) * 100 if len(dataset) > 0 else 0\n",
    "        bar = '‚ñà' * int(percentage / 5)\n",
    "        print(f\"   {emotion:10s}: {count:3d} samples ({percentage:5.1f}%) {bar}\")\n",
    "\n",
    "# ============================================================================\n",
    "# VERIFICA SPEAKER-INDEPENDENT SPLIT\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üîç VERIFICA SPEAKER-INDEPENDENT SPLIT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "train_actors = set([int(s['metadata']['actor']) for s in train_dataset.samples])\n",
    "val_actors = set([int(s['metadata']['actor']) for s in val_dataset.samples])\n",
    "test_actors = set([int(s['metadata']['actor']) for s in test_dataset.samples])\n",
    "\n",
    "print(f\"\\nüë• Attori per set:\")\n",
    "print(f\"   Train ({len(train_actors)} attori):      {sorted(train_actors)}\")\n",
    "print(f\"   Validation ({len(val_actors)} attori):   {sorted(val_actors)}\")\n",
    "print(f\"   Test ({len(test_actors)} attori):        {sorted(test_actors)}\")\n",
    "\n",
    "# Verifica overlap\n",
    "overlap_train_val = train_actors & val_actors\n",
    "overlap_train_test = train_actors & test_actors\n",
    "overlap_val_test = val_actors & test_actors\n",
    "\n",
    "print(f\"\\nüîé Verifica overlap attori:\")\n",
    "no_overlap = not overlap_train_val and not overlap_train_test and not overlap_val_test\n",
    "\n",
    "if no_overlap:\n",
    "    print(\"   ‚úÖ NESSUN OVERLAP! Split speaker-independent corretto!\")\n",
    "else:\n",
    "    print(\"   ‚ùå ATTENZIONE: Ci sono overlap!\")\n",
    "    if overlap_train_val:\n",
    "        print(f\"      Train-Validation overlap: {overlap_train_val}\")\n",
    "    if overlap_train_test:\n",
    "        print(f\"      Train-Test overlap: {overlap_train_test}\")\n",
    "    if overlap_val_test:\n",
    "        print(f\"      Validation-Test overlap: {overlap_val_test}\")\n",
    "\n",
    "# ============================================================================\n",
    "# VERIFICA BILANCIAMENTO GENERE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üë®üë© VERIFICA BILANCIAMENTO GENERE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for name, actors in [('Train', train_actors), ('Validation', val_actors), ('Test', test_actors)]:\n",
    "    males = [a for a in actors if a % 2 == 1]  # Dispari = maschi\n",
    "    females = [a for a in actors if a % 2 == 0]  # Pari = femmine\n",
    "    \n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"   üë® Maschi:  {len(males)} attori ‚Üí {sorted(males)}\")\n",
    "    print(f\"   üë© Femmine: {len(females)} attori ‚Üí {sorted(females)}\")\n",
    "    print(f\"   Ratio: {len(males)}M / {len(females)}F\")\n",
    "\n",
    "# ============================================================================\n",
    "# VERIFICA FILTRI SU CAMPIONI CASUALI\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üîç VERIFICA FILTRI SU CAMPIONI CASUALI\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "# Prendi 5 samples casuali dal training set\n",
    "sample_indices = random.sample(range(len(train_dataset)), min(5, len(train_dataset)))\n",
    "\n",
    "print(\"\\nüìã Verifica su 5 samples casuali dal training set:\")\n",
    "all_filters_ok = True\n",
    "\n",
    "for i, idx in enumerate(sample_indices, 1):\n",
    "    sample = train_dataset.samples[idx]\n",
    "    metadata = sample['metadata']\n",
    "    \n",
    "    # Verifica filtri\n",
    "    modality_ok = metadata['modality'] == '03'\n",
    "    vocal_ok = metadata['vocal_channel'] == '01'\n",
    "    emotion_ok = metadata['emotion'] in ['01', '03', '04', '05']\n",
    "    \n",
    "    status = \"‚úÖ\" if (modality_ok and vocal_ok and emotion_ok) else \"‚ùå\"\n",
    "    \n",
    "    print(f\"\\n  {status} Sample {i} (index {idx}):\")\n",
    "    print(f\"     üìÑ File: {sample['path'].name}\")\n",
    "    print(f\"     üé¨ Modality: {metadata['modality']} {'‚úì' if modality_ok else '‚úó (should be 03)'}\")\n",
    "    print(f\"     üé§ Vocal: {metadata['vocal_channel']} {'‚úì' if vocal_ok else '‚úó (should be 01)'}\")\n",
    "    print(f\"     üòä Emotion: {metadata['emotion']} ({metadata['emotion_label']}) {'‚úì' if emotion_ok else '‚úó'}\")\n",
    "    print(f\"     üë§ Actor: {metadata['actor']} ({'M' if int(metadata['actor']) % 2 == 1 else 'F'})\")\n",
    "    print(f\"     üí™ Intensity: {metadata['intensity']}\")\n",
    "    \n",
    "    if not (modality_ok and vocal_ok and emotion_ok):\n",
    "        all_filters_ok = False\n",
    "\n",
    "# ============================================================================\n",
    "# RIEPILOGO FINALE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úÖ RIEPILOGO FINALE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Verifica split fisso\n",
    "expected_train = set(range(1, 21))  # 1-20\n",
    "expected_val = {21, 22}\n",
    "expected_test = {23, 24}\n",
    "\n",
    "checks = []\n",
    "checks.append((\"Nessun overlap attori\", no_overlap))\n",
    "checks.append((\"Tutti i filtri corretti\", all_filters_ok))\n",
    "checks.append((\"4 emozioni presenti\", len(train_dataset) > 0 and len(val_dataset) > 0 and len(test_dataset) > 0))\n",
    "checks.append((\"Train: attori 1-20\", train_actors == expected_train))\n",
    "checks.append((\"Validation: attori 21-22\", val_actors == expected_val))\n",
    "checks.append((\"Test: attori 23-24\", test_actors == expected_test))\n",
    "\n",
    "print()\n",
    "for check_name, check_result in checks:\n",
    "    status = \"‚úÖ\" if check_result else \"‚ùå\"\n",
    "    print(f\"   {status} {check_name}\")\n",
    "\n",
    "all_checks = all(result for _, result in checks)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "if all_checks:\n",
    "    print(\"üéâ TUTTI I TEST SUPERATI! Dataset pronto per il training!\")\n",
    "    print(f\"üìä Split: {len(train_dataset)} train, {len(val_dataset)} val, {len(test_dataset)} test\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Alcuni test non sono passati. Controlla i messaggi sopra.\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3.7: Create DataLoader\n",
    "\n",
    "Create DataLoader for both Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.custom_ravdess_dataset import CustomRAVDESSDataset\n",
    "\n",
    "train_dataset = CustomRAVDESSDataset(dataset_root='./ravdess', split='train')\n",
    "val_dataset = CustomRAVDESSDataset(dataset_root='./ravdess', split='validation')\n",
    "test_dataset = CustomRAVDESSDataset(dataset_root='./ravdess', split='test')\n",
    "\n",
    "\n",
    "from utils.create_dataloaders import create_dataloaders\n",
    "\n",
    "train_loader, val_loader, test_loader = create_dataloaders(\n",
    "    train_dataset, val_dataset, test_dataset,\n",
    "    batch_size=32, device=device, dataset_name='RAVDESS'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sqo9Eh79yihI"
   },
   "source": [
    "# Step 4: Train your model and visualize training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4-dxDQOFcdgX"
   },
   "outputs": [],
   "source": [
    "#%env WANDB_API_KEY=\"7ade30086de7899bed412e3eb5c2da065c146f90\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "8q9OvEDHxmRv"
   },
   "outputs": [],
   "source": [
    "#!python train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DyQo3klIymlz"
   },
   "source": [
    "# Step 5: Evaluate your model\n",
    "\n",
    "1.   List item\n",
    "2.   List item\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9goKvp4jxk4j"
   },
   "outputs": [],
   "source": [
    "#!python eval.py"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
